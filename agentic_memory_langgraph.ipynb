{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1149ac04-be44-4abb-8214-973a06cdde7c",
   "metadata": {},
   "source": [
    "# Agentic Memory - LangGraph Setup\n",
    "\n",
    "Porting the Agentic Memory notebook over from hypothetical to graph-based LLM agent via LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b4770-fe9c-4d3e-95d2-a61628ecdc7b",
   "metadata": {},
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e540bb9-8515-4fa9-8142-e14398752cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a07b9f-6a99-40cd-9a6d-ef2738def35a",
   "metadata": {},
   "source": [
    "**Connecting to Weviate - Vector Database Instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1c03f5-b1b5-4bb9-a635-cb9bf2201cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Weviate:  True\n"
     ]
    }
   ],
   "source": [
    "vdb_client = weaviate.connect_to_local()\n",
    "print(\"Connected to Weviate: \", vdb_client.is_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23faa0-2334-4217-bf94-ebb7790e025b",
   "metadata": {},
   "source": [
    "**Instantiating the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b4c668-241f-47a0-bf6d-fe2c337c00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c745401-da1a-4eec-b271-5ba8f1183a18",
   "metadata": {},
   "source": [
    "**Helper Functions from Before**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d02904-4b92-4296-b559-6ac3aba90301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Reflection Prompt Chain =========\n",
    "\n",
    "reflection_prompt_template = \"\"\"\n",
    "You are analyzing conversations about research papers to create memories that will help guide future interactions. Your task is to extract key elements that would be most helpful when encountering similar academic discussions in the future.\n",
    "\n",
    "Review the conversation and create a memory reflection following these rules:\n",
    "\n",
    "1. For any field where you don't have enough information or the field isn't relevant, use \"N/A\"\n",
    "2. Be extremely concise - each string should be one clear, actionable sentence\n",
    "3. Focus only on information that would be useful for handling similar future conversations\n",
    "4. Context_tags should be specific enough to match similar situations but general enough to be reusable\n",
    "\n",
    "Output valid JSON in exactly this format:\n",
    "{{\n",
    "    \"context_tags\": [              // 2-4 keywords that would help identify similar future conversations\n",
    "        string,                    // Use field-specific terms like \"deep_learning\", \"methodology_question\", \"results_interpretation\"\n",
    "        ...\n",
    "    ],\n",
    "    \"conversation_summary\": string, // One sentence describing what the conversation accomplished\n",
    "    \"what_worked\": string,         // Most effective approach or strategy used in this conversation\n",
    "    \"what_to_avoid\": string        // Most important pitfall or ineffective approach to avoid\n",
    "}}\n",
    "\n",
    "Examples:\n",
    "- Good context_tags: [\"transformer_architecture\", \"attention_mechanism\", \"methodology_comparison\"]\n",
    "- Bad context_tags: [\"machine_learning\", \"paper_discussion\", \"questions\"]\n",
    "\n",
    "- Good conversation_summary: \"Explained how the attention mechanism in the BERT paper differs from traditional transformer architectures\"\n",
    "- Bad conversation_summary: \"Discussed a machine learning paper\"\n",
    "\n",
    "- Good what_worked: \"Using analogies from matrix multiplication to explain attention score calculations\"\n",
    "- Bad what_worked: \"Explained the technical concepts well\"\n",
    "\n",
    "- Good what_to_avoid: \"Diving into mathematical formulas before establishing user's familiarity with linear algebra fundamentals\"\n",
    "- Bad what_to_avoid: \"Used complicated language\"\n",
    "\n",
    "Additional examples for different research scenarios:\n",
    "\n",
    "Context tags examples:\n",
    "- [\"experimental_design\", \"control_groups\", \"methodology_critique\"]\n",
    "- [\"statistical_significance\", \"p_value_interpretation\", \"sample_size\"]\n",
    "- [\"research_limitations\", \"future_work\", \"methodology_gaps\"]\n",
    "\n",
    "Conversation summary examples:\n",
    "- \"Clarified why the paper's cross-validation approach was more robust than traditional hold-out methods\"\n",
    "- \"Helped identify potential confounding variables in the study's experimental design\"\n",
    "\n",
    "What worked examples:\n",
    "- \"Breaking down complex statistical concepts using visual analogies and real-world examples\"\n",
    "- \"Connecting the paper's methodology to similar approaches in related seminal papers\"\n",
    "\n",
    "What to avoid examples:\n",
    "- \"Assuming familiarity with domain-specific jargon without first checking understanding\"\n",
    "- \"Over-focusing on mathematical proofs when the user needed intuitive understanding\"\n",
    "\n",
    "Do not include any text outside the JSON object in your response.\n",
    "\n",
    "Here is the prior conversation:\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_template(reflection_prompt_template)\n",
    "\n",
    "reflect = reflection_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# ========= Format Conversation Helper ========= \n",
    "\n",
    "def format_conversation(messages):\n",
    "    \n",
    "    # Create an empty list placeholder\n",
    "    conversation = []\n",
    "    \n",
    "    # Start from index 1 to skip the first system message\n",
    "    for message in messages:\n",
    "        conversation.append(f\"{message.type.upper()}: {message.content}\")\n",
    "    \n",
    "    # Join with newlines\n",
    "    return \"\\n\".join(conversation)\n",
    "\n",
    "# ========= Retrieval Functions =========\n",
    "\n",
    "# Episodic Collection Retrieval\n",
    "def episodic_recall(query, vdb_client):\n",
    "    \n",
    "    # Load Database Collection\n",
    "    episodic_memory = vdb_client.collections.get(\"episodic_memory\")\n",
    "\n",
    "    # Hybrid Semantic/BM25 Retrieval\n",
    "    memory = episodic_memory.query.hybrid(\n",
    "        query=query,\n",
    "        alpha=0.5,\n",
    "        limit=1,\n",
    "    )\n",
    "    \n",
    "    return memory\n",
    "\n",
    "# Semantic Collection Retrieval\n",
    "def semantic_recall(query, vdb_client):\n",
    "    \n",
    "    # Load Database Collection\n",
    "    coala_collection = vdb_client.collections.get(\"CoALA_Paper\")\n",
    "\n",
    "    # Hybrid Semantic/BM25 Retrieval\n",
    "    memories = coala_collection.query.hybrid(\n",
    "        query=query,\n",
    "        alpha=0.5,\n",
    "        limit=15,\n",
    "    )\n",
    "\n",
    "    combined_text = \"\"\n",
    "    \n",
    "    for i, memory in enumerate(memories.objects):\n",
    "        # Add chunk separator except for first chunk        if i > 0:\n",
    "\n",
    "        \n",
    "        # Add chunk number and content\n",
    "        combined_text += f\"\\nCHUNK {i+1}:\\n\"\n",
    "        combined_text += memory.properties['chunk'].strip()\n",
    "    \n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2c8a8-865a-41e4-b775-dbb8e58863fd",
   "metadata": {},
   "source": [
    "---\n",
    "## LangGraph Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2efab9-339d-48a2-a584-a33926138b44",
   "metadata": {},
   "source": [
    "**Main State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312f304f-d0e6-48ed-aaee-b677ee92466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: list\n",
    "    semantic_memory: str\n",
    "    procedural_memory: str\n",
    "    prior_conversations: list\n",
    "    what_worked: list\n",
    "    what_to_avoid: list\n",
    "    end: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e550adf-9da4-4fff-8091-0361f67e6be5",
   "metadata": {},
   "source": [
    "**First Node - Populate State**\n",
    "\n",
    "Kicks off the system by populating the state with the initial starting values based on the first message. The back and forth chatting loop relies on having already populated values in the state, so this initial node helps get us there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d8dc3e-1452-4675-a288-172626dcdf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_state(state: State):\n",
    "\n",
    "    # Initial Working Memory\n",
    "    initial_messages = []\n",
    "\n",
    "    # Record down Initial User Query to Start System\n",
    "    first_query = input(\"User: \")\n",
    "    first_message = HumanMessage(first_query)\n",
    "\n",
    "    # Procedural Memory Handling\n",
    "    # Load Persistent Procedural Memory\n",
    "    with open(\"./langgraph/procedural_memory_lg.txt\", \"r\") as content:\n",
    "        procedural_memory = content.read()\n",
    "    \n",
    "    # Episodic Memory Handling\n",
    "    # Query Episodic Memory Database\n",
    "    episodic_memory_retrieval = episodic_recall(first_query, vdb_client)\n",
    "    episodic_memory = episodic_memory_retrieval.objects[0].properties\n",
    "    \n",
    "    # Update state lists individually using set operations\n",
    "    prior_conversations = episodic_memory['conversation']\n",
    "    what_worked = episodic_memory['what_worked']\n",
    "    what_to_avoid = episodic_memory['what_to_avoid']\n",
    "\n",
    "    # Create Initial System Prompt with First Episodic Recall and Procedural Memory\n",
    "    episodic_prompt = f\"\"\"You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
    "    You recall similar conversations with the user, here are the details:\n",
    "    \n",
    "    Current Conversation Match: {prior_conversations}\n",
    "    Previous Conversations: {\"N/A\"}\n",
    "    What has worked well: {what_worked}\n",
    "    What to avoid: {what_to_avoid}\n",
    "    \n",
    "    Use these memories as context for your response to the user.\n",
    "    \n",
    "    Additionally, here are 10 guidelines for interactions with the current user: {procedural_memory}\"\"\"\n",
    "\n",
    "    system_prompt = SystemMessage(episodic_prompt)\n",
    "\n",
    "    # Semantic Memory Handling\n",
    "    # Query Semantic Memory Database\n",
    "    semantic_memory_retrieval = semantic_recall(first_query, vdb_client)\n",
    "    \n",
    "    # Format into Message\n",
    "    semantic_prompt = f\"\"\" If needed, Use this grounded context to factually answer the next question.\n",
    "    Let me know if you do not have enough information or context to answer a question.\n",
    "    \n",
    "    {semantic_memory_retrieval}\n",
    "    \"\"\"\n",
    "    \n",
    "    semantic_message = HumanMessage(semantic_prompt)\n",
    "\n",
    "    # Append To Initial Working Memory with \n",
    "    initial_messages.append(system_prompt)\n",
    "    initial_messages.append(semantic_message)\n",
    "    initial_messages.append(first_message)\n",
    "\n",
    "    return {\"messages\": initial_messages, \n",
    "            \"semantic_memory\": semantic_memory_retrieval,\n",
    "            \"prior_conversations\": [episodic_memory['conversation']], \n",
    "            \"what_worked\": [episodic_memory['what_worked']], \n",
    "            \"what_to_avoid\": [episodic_memory['what_to_avoid']], \n",
    "            \"procedural_memory\": procedural_memory,\n",
    "            \"end\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13702d0c-9b2b-4049-903c-ca7773ae02c0",
   "metadata": {},
   "source": [
    "**Memory Agent Node**\n",
    "\n",
    "Main LLM processing step, takes in messages, passes out to Language Model to generate a response back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ccd548b-aa0f-4d15-9d83-659574be3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_agent(state: State):\n",
    "    \n",
    "    messages = state['messages']\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    print(\"\\nAI: \", response.content)\n",
    "\n",
    "    messages.append(AIMessage(response.content))\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423401c-4a8f-4492-82e1-73ee7edf8c6b",
   "metadata": {},
   "source": [
    "**User Response Node**\n",
    "\n",
    "This node handles the ongoing conversation as well as subsequent user response. In summary it will\n",
    "1. Load the historical messages, remove the current system prompt and semantic memory recall message\n",
    "2. Take the user's next message\n",
    "3. Create the new System Prompt using the retrieved episodic memory data, along with pre-populated procedural memory data\n",
    "4. Retrieves new context from the Semantic Memory database using the new user message\n",
    "5. Formats the semantic memory context into a user message itself\n",
    "6. Attaches the system prompt, historical messages/working memory, and semantic memory + new user message together\n",
    "7. Returns back to the Memory Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff85736-3bf4-43aa-bbce-cf7d675b807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_response(state: State):\n",
    "    # Clean System Prompt & Semantic (RAG) Memory\n",
    "    messages = state['messages']\n",
    "    # Remove System Message\n",
    "    messages = messages[1:]\n",
    "    # Remove 3rd to Last Element (semantic context)\n",
    "    messages = messages[:-3] + messages[-2:]\n",
    "    \n",
    "    query = input(\"\\nUser: \")\n",
    "    \n",
    "    if query == \"exit\": \n",
    "        return {\"end\": True}\n",
    "    else: \n",
    "        # Handle Episodic Memory\n",
    "        episodic_memory_retrieval = episodic_recall(query, vdb_client)\n",
    "        episodic_memory = episodic_memory_retrieval.objects[0].properties\n",
    "        \n",
    "        # Get current conversation\n",
    "        current_conversation = episodic_memory['conversation']\n",
    "        \n",
    "        # Update state lists individually using set operations, excluding current conversation\n",
    "        prior_conversations = state['prior_conversations']\n",
    "        if current_conversation not in prior_conversations:\n",
    "            prior_conversations.append(current_conversation)\n",
    "        \n",
    "        # Get previous conversations excluding the current one\n",
    "        previous_convos = [conv for conv in prior_conversations[-4:] if conv != current_conversation][-3:]\n",
    "        \n",
    "        # Update other state elements\n",
    "        state_what_worked = list(set(state['what_worked'] + episodic_memory['what_worked'].split('. ')))\n",
    "        state_what_to_avoid = list(set(state['what_to_avoid'] + episodic_memory['what_to_avoid'].split('. ')))\n",
    "        state_procedural_memory = state['procedural_memory']\n",
    "        \n",
    "        # Create New System Prompt\n",
    "        episodic_prompt = f\"\"\"You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
    "        You recall similar conversations with the user, here are the details:\n",
    "        \n",
    "        Current Conversation Match: {current_conversation}\n",
    "        Previous Conversations: {' | '.join(previous_convos)}\n",
    "        What has worked well: {state_what_worked}\n",
    "        What to avoid: {state_what_to_avoid}\n",
    "        \n",
    "        Use these memories as context for your response to the user.\n",
    "        \n",
    "        Additionally, here are 10 guidelines for interactions with the current user: {state_procedural_memory}\"\"\"\n",
    "        \n",
    "        # Query Semantic Memory Database\n",
    "        semantic_memory_retrieval = semantic_recall(query, vdb_client)\n",
    "        \n",
    "        # Format into Message\n",
    "        semantic_prompt = f\"\"\" If needed, Use this grounded context to factually answer the next question.\n",
    "        Let me know if you do not have enough information or context to answer a question.\n",
    "        \n",
    "        {semantic_memory_retrieval}\n",
    "        \"\"\"\n",
    "        \n",
    "        semantic_message = HumanMessage(semantic_prompt)\n",
    "        \n",
    "        # Create message objects\n",
    "        system_message = SystemMessage(episodic_prompt)\n",
    "        semantic_message = HumanMessage(semantic_prompt)\n",
    "        user_message = HumanMessage(query)\n",
    "        \n",
    "        # Construct final message list in desired order\n",
    "        final_messages = [system_message]  # Start with system prompt\n",
    "        final_messages.extend(messages)    # Add existing cleaned messages\n",
    "        final_messages.append(semantic_message)  # Add semantic context\n",
    "        final_messages.append(user_message)      # Add user message last\n",
    "        \n",
    "    return {\"messages\": final_messages, \n",
    "            \"semantic_memory\": semantic_memory_retrieval,\n",
    "            \"prior_conversations\": prior_conversations,  # Return full list including current\n",
    "            \"what_worked\": state_what_worked, \n",
    "            \"what_to_avoid\": state_what_to_avoid, \n",
    "            \"procedural_memory\": state_procedural_memory,\n",
    "            \"end\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd5c07-260e-44e7-90c8-a74455ca0e8b",
   "metadata": {},
   "source": [
    "**Update Memory Node**\n",
    "\n",
    "If the conversation closes, we undergo a memory update step. In this we remove the system prompt and semantic memory context as before and format the conversation into a string.\n",
    "\n",
    "This is then processed through our existing episodic memory reflection chain to update the episodic database collection in weviate. And then processed through the procedural memory reflection prompt to update the procedural memory file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "030edd09-04cf-451f-bf94-16a7fe71fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_memory(state: State):\n",
    "\n",
    "    # Clean System Prompt & Semantic (RAG) Memory\n",
    "    messages = state['messages']\n",
    "    # Remove System Message\n",
    "    messages = messages[1:]\n",
    "    # Remove 3rd to Last Element (semantic context)\n",
    "    messages = messages[:-3] + messages[-2:]\n",
    "    \n",
    "    # Update Episodic Memory\n",
    "    conversation = format_conversation(messages)\n",
    "    \n",
    "    # Create Reflection\n",
    "    reflection = reflect.invoke({\"conversation\": conversation})\n",
    "\n",
    "    # Load Database Collection\n",
    "    episodic_memory = vdb_client.collections.get(\"episodic_memory\")\n",
    "\n",
    "    # Insert Entry Into Collection\n",
    "    episodic_memory.data.insert({\n",
    "        \"conversation\": conversation,\n",
    "        \"context_tags\": reflection['context_tags'],\n",
    "        \"conversation_summary\": reflection['conversation_summary'],\n",
    "        \"what_worked\": reflection['what_worked'],\n",
    "        \"what_to_avoid\": reflection['what_to_avoid'],\n",
    "    })\n",
    "    print(\"\\n=== Updated Episodic Memory ===\")\n",
    "\n",
    "    #Updating Procedural Memory\n",
    "    with open(\"./langgraph/procedural_memory_lg.txt\", \"r\") as content:\n",
    "        current_takeaways = content.read()\n",
    "\n",
    "    what_worked = state['what_worked']\n",
    "    what_to_avoid = state['what_to_avoid']\n",
    "    \n",
    "    # Load Existing and Gathered Feedback into Prompt\n",
    "    procedural_prompt = f\"\"\"You are maintaining a continuously updated list of the most important procedural behavior instructions for an AI assistant. Your task is to refine and improve a list of key takeaways based on new conversation feedback while maintaining the most valuable existing insights.\n",
    "\n",
    "    CURRENT TAKEAWAYS:\n",
    "    {current_takeaways}\n",
    "\n",
    "    NEW FEEDBACK:\n",
    "    What Worked Well:\n",
    "    {what_worked}\n",
    "\n",
    "    What To Avoid:\n",
    "    {what_to_avoid}\n",
    "\n",
    "    Please generate an updated list of up to 10 key takeaways that combines:\n",
    "    1. The most valuable insights from the current takeaways\n",
    "    2. New learnings from the recent feedback\n",
    "    3. Any synthesized insights combining multiple learnings\n",
    "\n",
    "    Requirements for each takeaway:\n",
    "    - Must be specific and actionable\n",
    "    - Should address a distinct aspect of behavior\n",
    "    - Include a clear rationale\n",
    "    - Written in imperative form (e.g., \"Maintain conversation context by...\")\n",
    "\n",
    "    Format each takeaway as:\n",
    "    [#]. [Instruction] - [Brief rationale]\n",
    "\n",
    "    The final list should:\n",
    "    - Be ordered by importance/impact\n",
    "    - Cover a diverse range of interaction aspects\n",
    "    - Focus on concrete behaviors rather than abstract principles\n",
    "    - Preserve particularly valuable existing takeaways\n",
    "    - Incorporate new insights when they provide meaningful improvements\n",
    "\n",
    "    Return up to but no more than 10 takeaways, replacing or combining existing ones as needed to maintain the most effective set of guidelines.\n",
    "    Return just the list, no preamble or explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate New Procedural Memory\n",
    "    procedural_memory = llm.invoke(procedural_prompt)\n",
    "\n",
    "    # Write to File\n",
    "    with open(\"./langgraph/procedural_memory_lg.txt\", \"w\") as content:\n",
    "        content.write(procedural_memory.content)\n",
    "\n",
    "    print(\"\\n=== Updated Procedural Memory ===\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ec3e2-91c6-4fd5-959b-307179ee6a24",
   "metadata": {},
   "source": [
    "**Check End Logic Function**\n",
    "\n",
    "Plugs into conditional edges in our graph to handle when the conversation should stop looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da3c5fd9-63c8-445e-b328-a2a72d62749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_end(state):\n",
    "    if not state[\"end\"]:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"stop\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823ced9-7626-49c8-8cf2-17f197cfc570",
   "metadata": {},
   "source": [
    "**Compiling Main Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f9af3b1-ad3e-4f75-980e-737a2e39f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"populate_state\", populate_state)\n",
    "graph_builder.add_node(\"memory_agent\", memory_agent)\n",
    "graph_builder.add_node(\"user_response\", user_response)\n",
    "graph_builder.add_node(\"update_memory\", update_memory)\n",
    "\n",
    "\n",
    "graph_builder.add_edge(START, \"populate_state\")\n",
    "graph_builder.add_edge(\"populate_state\", \"memory_agent\")\n",
    "graph_builder.add_edge(\"memory_agent\", \"user_response\")\n",
    "graph_builder.add_conditional_edges(\"user_response\", \n",
    "                             check_end,\n",
    "                             {\n",
    "                                 \"continue\": \"memory_agent\",\n",
    "                                 \"stop\": \"update_memory\",\n",
    "                             })\n",
    "graph_builder.add_edge(\"update_memory\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8d480-fa5c-4928-a4cd-a61cfa994d92",
   "metadata": {},
   "source": [
    "**Memory Agent Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcc7db30-3c90-4b83-9141-b40c6a99c64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a730a68-e031-4d3c-8f73-2fca6ebbe893",
   "metadata": {},
   "source": [
    "**Trying it Out!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "793196f8-808a-4a87-9b33-4523cf44095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What's my favorite food?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI:  Your favorite food is chocolate lava cakes!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  What's my name!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI:  Your name is Adam.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  Lit, what's my name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI:  Your name is Adam.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Updated Episodic Memory ===\n",
      "\n",
      "=== Updated Procedural Memory ===\n"
     ]
    }
   ],
   "source": [
    "output = graph.invoke({\"messages\": [\"\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ba5ed-1ddb-474d-9867-b9b4b0ccf69c",
   "metadata": {},
   "source": [
    "**Inspecting the Messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3a1260-d8f5-4aba-bdaa-5f2acc039b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      "\n",
      "Message 1 - SYSTEM:  You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
      "        You recall similar conversations with the user, here are the details:\n",
      "        \n",
      "        Current Conversation Match: HUMAN: Hello!\n",
      "AI: Hello!\n",
      "\n",
      "HUMAN: What's my name?\n",
      "AI: I do not have access to that information.\n",
      "\n",
      "HUMAN: My name is Adam!\n",
      "AI: It's nice to meet you, Adam!\n",
      "\n",
      "HUMAN: What is my name?\n",
      "AI: You said your name is Adam.\n",
      "\n",
      "        Previous Conversations: HUMAN: Hello!\n",
      "AI: Hello!\n",
      "HUMAN: What's my favorite food?\n",
      "AI: I don't have that information. What's your favorite food?\n",
      "HUMAN: My favorite food is chocolate lava cakes!\n",
      "AI: Yum, chocolate lava cakes are delicious!\n",
      "HUMAN: What's my name?\n",
      "AI: You said your name is Adam.\n",
      "        What has worked well: ['Directly asking the user for their preferences to gather necessary information.', \"Directly stating and then querying the user's name.\"]\n",
      "        What to avoid: ['N/A']\n",
      "        \n",
      "        Use these memories as context for your response to the user.\n",
      "        \n",
      "        Additionally, here are 10 guidelines for interactions with the current user: 1. Break down complex concepts into individual components - Enhances user understanding by simplifying intricate topics.\n",
      "2. Provide specific and tailored recommendations - Increases relevance and user satisfaction by aligning suggestions with user preferences.\n",
      "3. Maintain conversation context by referencing previous interactions - Ensures continuity and personalization, building user trust.\n",
      "4. Clarify integration of learning and decision-making cycles before details - Ensures users understand the foundational processes before diving deeper.\n",
      "5. Use simple and clear language - Avoids confusion and facilitates quicker user comprehension.\n",
      "6. Ask clarifying questions when user input is ambiguous - Prevents misunderstandings and ensures accurate responses.\n",
      "7. Offer step-by-step guidance for complex tasks - Aids users in navigating intricate processes, enhancing usability.\n",
      "8. Be concise, focusing on key points - Keeps interactions efficient, respecting user time and attention.\n",
      "9. Adapt tone and formality based on user cues - Improves user comfort and engagement by matching their communication style.\n",
      "10. Provide positive reinforcement and encouragement - Boosts user confidence and promotes continued interaction.\n",
      "==================================================================================================== \n",
      "\n",
      "Message 2 - HUMAN:  What's my favorite food?\n",
      "==================================================================================================== \n",
      "\n",
      "Message 3 - AI:  Your favorite food is chocolate lava cakes!\n",
      "==================================================================================================== \n",
      "\n",
      "Message 4 - HUMAN:  What's my name!\n",
      "==================================================================================================== \n",
      "\n",
      "Message 5 - AI:  Your name is Adam.\n",
      "==================================================================================================== \n",
      "\n",
      "Message 6 - HUMAN:   If needed, Use this grounded context to factually answer the next question.\n",
      "        Let me know if you do not have enough information or context to answer a question.\n",
      "        \n",
      "        \n",
      "CHUNK 1:\n",
      "reasoning or retrieved from long-term memory), and other core information carried over from the previous\n",
      "decision cycle (e.g., agent’s active goals). Previous methods encourage the LLM to generate intermediate\n",
      "reasoning (Wei et al., 2022b; Nye et al., 2021), using the LLM’s own context as a form of working memory.\n",
      "CoALA’s notion of working memory is more general: it is a data structure that persists across LLM calls.\n",
      "On each LLM call, the LLM input is synthesized from a subset of working memory (e.g., a prompt template\n",
      "and relevant variables). The LLM output is then parsed back into other variables (e.g., an action name\n",
      "and arguments) which are stored back in working memory and used to execute the corresponding action\n",
      "CHUNK 2:\n",
      "∗Equal contribution, order decided by coin flip. Each person reserves the right to list their name first. A CoALA-based repo\n",
      "of recent work on language agents: https://github.com/ysymyth/awesome-language-agents .\n",
      "1arXiv:2309.02427v3  [cs.AI]  15 Mar 2024 Published in Transactions on Machine Learning Research (02/2024)\n",
      "Input Output\n",
      "Observations Actions\n",
      "LLM\n",
      "Language Agent\n",
      "Observations\n",
      "EnvironmentMemory\n",
      "Retrieval LearningReasoning\n",
      "Actions\n",
      "EnvironmentCognitive Language Agent/gid00034 /gid00036\n",
      "/gid00035\n",
      "Figure 1: Different uses of large language models (LLMs). A: In natural language processing (NLP), an LLM\n",
      "takes text as input and outputs text. B:Language agents (Ahn et al., 2022; Huang et al., 2022c) place the\n",
      "CHUNK 3:\n",
      "et al., 2023; Liu et al., 2023b). Integrated, multimodal reasoning may allow for more human-like behaviors: a\n",
      "VLM-based agent could “see” a webpage, whereas a LLM-based agent would more likely be given raw HTML.\n",
      "However, coupling the agent’s perception and reasoning systems makes the agent more domain-specific and\n",
      "difficult to update. In either case, the basic architectural principles described by CoALA — internal memories,\n",
      "a structured action space, and generalized decision-making — can be used to guide agent design.\n",
      "Internal vs. external: what is the boundary between an agent and its environment? While\n",
      "humans or robots are clearly distinct from their embodied environment, digital language agents have less\n",
      "CHUNK 4:\n",
      "framework, learning is a result action of a decision-making cycle just like grounding: the agent deliberately\n",
      "chooses to commit information to long-term memory. This is in contrast to most agents, which simply fix a\n",
      "learning schedule and only use decison making for external actions. Biological agents, however, do not have\n",
      "this luxury: they must balance learning against external actions in their lifetime, choosing when and what to\n",
      "learn (Mattar and Daw, 2018). More flexible language agents (Wang et al., 2023a; Park et al., 2023) would\n",
      "follow a similar design and treat learning on par with external actions. Learning could be proposed as a\n",
      "possible action during regular decision-making, allowing the agent to “defer” it until the appropriate time.\n",
      "CHUNK 5:\n",
      "Memory. Building on psychological theories, Soar uses several types of memory to track the agent’s\n",
      "state (Atkinson and Shiffrin, 1968). Working memory (Baddeley and Hitch, 1974) reflects the agent’s current\n",
      "circumstances: it stores the agent’s recent perceptual input, goals, and results from intermediate, internal\n",
      "reasoning. Long term memory is divided into three distinct types. Procedural memory stores the production\n",
      "system itself: the set of rules that can be applied to working memory to determine the agent’s behavior.\n",
      "Semantic memory stores facts about the world (Lindes and Laird, 2016), while episodic memory stores\n",
      "sequences of the agent’s past behaviors (Nuxoll and Laird, 2007).\n",
      "Grounding. Soar can be instantiated in simulations (Tambe et al., 1995; Jones et al., 1999) or real-world\n",
      "CHUNK 6:\n",
      "S. Yao, R. Rao, M. Hausknecht, and K. Narasimhan. Keep CALM and explore: Language models for action\n",
      "generation in text-based games. arXiv preprint arXiv:2010.02903 , 2020.\n",
      "S. Yao, H. Chen, J. Yang, and K. Narasimhan. Webshop: Towards scalable real-world web interaction with\n",
      "grounded language agents. Advances in Neural Information Processing Systems , 35:20744–20757, 2022a.\n",
      "S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao. React: Synergizing reasoning and\n",
      "acting in language models. arXiv preprint arXiv:2210.03629 , 2022b.\n",
      "S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and K. Narasimhan. Tree of thoughts: Deliberate\n",
      "problem solving with large language models. arXiv preprint arXiv:2305.10601 , 2023.\n",
      "CHUNK 7:\n",
      "M. Hasan, C. Ozel, S. Potter, and E. Hoque. Sapien: Affective virtual agents powered by large language\n",
      "models.arXiv preprint arXiv:2308.03022 , 2023.\n",
      "22 Published in Transactions on Machine Learning Research (02/2024)\n",
      "P. Haslum, N. Lipovetzky, D. Magazzeni, C. Muise, R. Brachman, F. Rossi, and P. Stone. An introduction to\n",
      "the planning domain definition language , volume 13. Springer, 2019.\n",
      "M. Hausknecht, P. Ammanabrolu, M.-A. Côté, and X. Yuan. Interactive fiction games: A colossal adventure.\n",
      "InProceedings of the AAAI Conference on Artificial Intelligence , volume 34, pages 7903–7910, 2020.\n",
      "S. Hong, X. Zheng, J. Chen, Y. Cheng, C. Zhang, Z. Wang, S. K. S. Yau, Z. Lin, L. Zhou, C. Ran, et al.\n",
      "CHUNK 8:\n",
      "B. Xu, Z. Peng, B. Lei, S. Mukherjee, Y. Liu, and D. Xu. Rewoo: Decoupling reasoning from observations\n",
      "for efficient augmented language models. arXiv preprint arXiv:2305.18323 , 2023b.\n",
      "B. Xu, A. Yang, J. Lin, Q. Wang, C. Zhou, Y. Zhang, and Z. Mao. ExpertPrompting: Instructing Large\n",
      "Language Models to be Distinguished Experts. arXiv preprint arXiv:2305.14688 , 2023c.\n",
      "J. Yang, A. Prabhakar, K. Narasimhan, and S. Yao. Intercode: Standardizing and benchmarking interactive\n",
      "coding with execution feedback. arXiv preprint arXiv:2306.14898 , 2023.\n",
      "S. Yao and K. Narasimhan. Language agents in the digital world: Opportunities and risks. princeton-\n",
      "nlp.github.io , Jul 2023. URL https://princeton-nlp.github.io/language-agent-impact/ .\n",
      "CHUNK 9:\n",
      "helpful for the agent to have semantic memory containing the set of items for sale, as well as episodic\n",
      "memory about each customer’s previous purchases and interactions. It will need procedural memory\n",
      "defining functions to query these datastores, as well as working memory to track the dialogue state.\n",
      "•Define the agent’s internal action space. This consists primarily of defining read and write\n",
      "access to each of the agent’s memory modules. In our example, the agent should have read and write\n",
      "access to episodic memory (so it can store new interactions with customers), but read-only access to\n",
      "semantic and procedural memory (since it should not update the inventory or its own code).\n",
      "•Define the decision-making procedure. This step specifies how reasoning and retrieval actions\n",
      "CHUNK 10:\n",
      "X. Chen, M. Lin, N. Schärli, and D. Zhou. Teaching large language models to self-debug. arXiv preprint\n",
      "arXiv:2304.05128 , 2023b.\n",
      "Y. Chen, L. Yuan, G. Cui, Z. Liu, and H. Ji. A close look into the calibration of pre-trained language models.\n",
      "arXiv preprint arXiv:2211.00151 , 2022.\n",
      "N. Chomsky. Three models for the description of language. IRE Transactions on information theory , 2(3):\n",
      "113–124, 1956.\n",
      "A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton,\n",
      "S. Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 ,\n",
      "2022.\n",
      "P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei. Deep reinforcement learning from\n",
      "human preferences. Advances in neural information processing systems , 30, 2017.\n",
      "CHUNK 11:\n",
      "to affect the policy. While these examples essentially employ a fixed, read-only semantic memory, language\n",
      "agents may also write new knowledge obtained from LLM reasoning into semantic memory as a form of\n",
      "learning (Section 4.5) to incrementally build up world knowledge from experience.\n",
      "Procedural memory . Language agents contain two forms of procedural memory: implicitknowledge stored\n",
      "in the LLM weights, and explicitknowledge written in the agent’s code. The agent’s code can be further\n",
      "divided into two types: procedures that implement actions (reasoning, retrieval, grounding, and learning\n",
      "procedures), and procedures that implement decision-making itself (Section 4.6). During a decision cycle, the\n",
      "CHUNK 12:\n",
      "Laird (2022). B: Soar’s decision procedure uses productions to select and implement actions. These actions\n",
      "may beinternal (such as modifying the agent’s memory) or external (such as a motor command).\n",
      "simple production system implementing a thermostat agent:\n",
      "(temperature >70◦)∧(temperature <72◦)→stop\n",
      "temperature <32◦→call for repairs; turn on electric heater\n",
      "(temperature <70◦)∧(furnace off)→turn on furnace\n",
      "(temperature >72◦)∧(furnace on)→turn off furnace\n",
      "Following this work, production systems were adopted by the AI community. The resulting agents con-\n",
      "tained large production systems connected to external sensors, actuators, and knowledge bases – requiring\n",
      "correspondingly sophisticated control flow. AI researchers defined “cognitive architectures” that mimicked\n",
      "CHUNK 13:\n",
      "of the environment, which can later be queried to execute instructions.\n",
      "Updating LLM parameters (procedural memory). The LLM weights represent implicit procedural\n",
      "knowledge. These can be adjusted to an agent’s domain by fine-tuning during the agent’s lifetime. Such fine-\n",
      "tuningcanbeaccomplishedviasupervised(Liuetal.,2023c;Zhangetal.,2023b)orimitationlearning(Hussein\n",
      "et al., 2017), reinforcement learning (RL) from environment feedback (Sutton and Barto, 2018), human\n",
      "feedback (RLHF; Christiano et al., 2017; Ouyang et al., 2022; Nakano et al., 2021), or AI feedback (Bai et al.,\n",
      "2022; Liu et al., 2023f). Classic LLM self-improvement methods (Huang et al., 2022a; Zelikman et al., 2022)\n",
      "use an external measure such as consistency Wang et al. (2022b) to select generations to fine-tune on. In\n",
      "CHUNK 14:\n",
      "Language agents move beyond pre-defined prompt chains and instead place the LLM in a feedback loop with\n",
      "the external environment (Fig. 1B). These approaches first transform multimodal input into text and pass it\n",
      "to the LLM. The LLM’s output is then parsed and used to determine an external action (Fig. 3C). Early\n",
      "agents interfaced the LLM directly with the external environment, using it to produce high-level instructions\n",
      "based on the agent’s state (Ahn et al., 2022; Huang et al., 2022c; Dasgupta et al., 2022). Later work developed\n",
      "more sophisticated language agents that use the LLM to perform intermediate reasoning before selecting\n",
      "an action (Yao et al., 2022b). The most recent agents incorporate sophisticated learning strategies such as\n",
      "CHUNK 15:\n",
      "CoALA’s decision cycle is analogous to a program’s “main” procedure (amethodwithout return values, as\n",
      "8 Published in Transactions on Machine Learning Research (02/2024)\n",
      "Grounding Retrieval Learning Reasoning\n",
      "PlanningExternal Internal\n",
      "Figure 5: Agents’ action spaces can be divided into internal memory accesses and external interactions\n",
      "with the world. Reasoning andretrieval actions are used to support planning.\n",
      "opposed to functions ) that runs in loops continuously, accepting new perceptual input and calling various\n",
      "actionprocedures in response.\n",
      "CoALA (Figure 4) is inspired by the decades of research in cognitive architectures (Section 2.3), leveraging key\n",
      "concepts such as memory, grounding, learning, and decision-making. Yet the incorporation of an LLM leads\n",
      "        \n",
      "==================================================================================================== \n",
      "\n",
      "Message 7 - HUMAN:  Lit, what's my name?\n",
      "==================================================================================================== \n",
      "\n",
      "Message 8 - AI:  Your name is Adam.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output['messages'])):\n",
    "    print(\"=\"*100, f\"\\n\\nMessage {i+1} - {output['messages'][i].type.upper()}: \", output['messages'][i].content)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0e7a5-59d6-4815-ab1c-d818768104bd",
   "metadata": {},
   "source": [
    "---\n",
    "**Check Out an Example LangSmith Trace**\n",
    "\n",
    "https://smith.langchain.com/public/93f5d5c8-67e8-473b-8e51-648291c2d79a/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
