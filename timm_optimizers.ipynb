{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wiyxqbfvrGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13924f5-d918-49c7-971b-522ba629f8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/pytorch-image-models.git\n",
            "  Cloning https://github.com/huggingface/pytorch-image-models.git to /tmp/pip-req-build-ttof0hei\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/pytorch-image-models.git /tmp/pip-req-build-ttof0hei\n",
            "  Resolved https://github.com/huggingface/pytorch-image-models.git to commit 0b5264a108890f87317558e89adf643f4b330884\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm==1.0.12.dev0) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==1.0.12.dev0) (0.20.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==1.0.12.dev0) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm==1.0.12.dev0) (0.26.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==1.0.12.dev0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm==1.0.12.dev0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm==1.0.12.dev0) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm==1.0.12.dev0) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm==1.0.12.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm==1.0.12.dev0) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm==1.0.12.dev0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm==1.0.12.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm==1.0.12.dev0) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm==1.0.12.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm==1.0.12.dev0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==1.0.12.dev0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==1.0.12.dev0) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm==1.0.12.dev0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm==1.0.12.dev0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm==1.0.12.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm==1.0.12.dev0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm==1.0.12.dev0) (2024.8.30)\n",
            "Building wheels for collected packages: timm\n",
            "  Building wheel for timm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timm: filename=timm-1.0.12.dev0-py3-none-any.whl size=2342090 sha256=2db512d47f33389eef15e185c7846b8fd6eceb5632362c675242acdb6579ce27\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7w4hkay2/wheels/db/23/a2/e7496a9eafb64fb93606c0ba3d59675246b74aa78939b80e39\n",
            "Successfully built timm\n",
            "Installing collected packages: timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.11\n",
            "    Uninstalling timm-1.0.11:\n",
            "      Successfully uninstalled timm-1.0.11\n",
            "Successfully installed timm-1.0.12.dev0\n"
          ]
        }
      ],
      "source": [
        "# timm is in colab by default now, but we need the main branch to show new optimizer features\n",
        "!pip install git+https://github.com/huggingface/pytorch-image-models.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm.optim"
      ],
      "metadata": {
        "id": "VmgUJ5PbzS4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all optimizers (with descriptions) available through timm factory, includes torch.optim, and also select bitsandbytes (bnb) and APEX (fused) optimizers.\n",
        "for k,v in timm.optim.list_optimizers(with_description=True):\n",
        "    print(f'{k}: {v}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqOUgtzezUZg",
        "outputId": "7cdb3460-cc67-4585-a383-cb9f82d3c685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adabelief: Adapts learning rate based on gradient prediction error\n",
            "adadelta: torch.optim Adadelta, Adapts learning rates based on running windows of gradients\n",
            "adafactor: Memory-efficient implementation of Adam with factored gradients\n",
            "adafactorbv: Big Vision variant of Adafactor with factored gradients, half precision momentum\n",
            "adagrad: torch.optim Adagrad, Adapts learning rates using cumulative squared gradients\n",
            "adahessian: An Adaptive Second Order Optimizer\n",
            "adam: torch.optim Adam (Adaptive Moment Estimation)\n",
            "adamax: torch.optim Adamax, Adam with infinity norm for more stable updates\n",
            "adamp: Adam with built-in projection to unit norm sphere\n",
            "adamw: torch.optim Adam with decoupled weight decay regularization\n",
            "adan: Adaptive Nesterov Momentum Algorithm\n",
            "adanw: Adaptive Nesterov Momentum with decoupled weight decay\n",
            "adopt: Modified Adam that can converge with any β2 with the optimal rate\n",
            "adoptw: Modified AdamW (decoupled decay) that can converge with any β2 with the optimal rate\n",
            "bnbadam: bitsandbytes Adam\n",
            "bnbadam8bit: bitsandbytes 8-bit Adam with dynamic quantization\n",
            "bnbadamw: bitsandbytes AdamW\n",
            "bnbadamw8bit: bitsandbytes 8-bit AdamW with dynamic quantization\n",
            "bnbademamix: bitsandbytes AdEMAMix\n",
            "bnbademamix8bit: bitsandbytes 8-bit AdEMAMix with dynamic quantization\n",
            "bnblion: bitsandbytes Lion\n",
            "bnblion8bit: bitsandbytes 8-bit Lion with dynamic quantization\n",
            "bnbsgd: bitsandbytes SGD\n",
            "bnbsgd8bit: bitsandbytes 8-bit SGD with dynamic quantization\n",
            "fusedadam: NVIDIA APEX fused Adam implementation\n",
            "fusedadamw: NVIDIA APEX fused AdamW implementation\n",
            "fusedlamb: NVIDIA APEX fused LAMB implementation\n",
            "fusednovograd: NVIDIA APEX fused NovoGrad implementation\n",
            "fusedsgd: NVIDIA APEX fused SGD implementation for faster training\n",
            "lamb: Layer-wise Adaptive Moments for batch optimization\n",
            "lambc: LAMB with trust ratio clipping for stability\n",
            "larc: LARS with trust ratio clipping for stability\n",
            "lars: Layer-wise Adaptive Rate Scaling\n",
            "lion: Evolved Sign Momentum optimizer for improved convergence\n",
            "madgrad: Momentum-based Adaptive gradient method\n",
            "madgradw: MADGRAD with decoupled weight decay\n",
            "momentum: torch.Optim Stochastic Gradient Descent (SGD) with classical momentum\n",
            "nadam: Adam with Nesterov momentum\n",
            "nadamw: Adam with Nesterov momentum and decoupled weight decay\n",
            "nesterov: torch.Optim Stochastic Gradient Descent (SGD) with Nesterov momentum\n",
            "nesterovw: SGD with decoupled weight decay and Nesterov momentum\n",
            "nlarc: LARS with Nesterov momentum & trust ratio clipping\n",
            "nlars: LARS with Nesterov momentum\n",
            "novograd: Normalized Adam with L2 norm gradient normalization\n",
            "radabelief: Rectified AdaBelief with variance adaptation\n",
            "radam: Rectified Adam with variance adaptation\n",
            "rmsprop: torch.optim RMSprop, Root Mean Square Propagation\n",
            "rmsproptf: TensorFlow-style RMSprop implementation, Root Mean Square Propagation\n",
            "sgd: torch.Optim Stochastic Gradient Descent (SGD) with Nesterov momentum\n",
            "sgdp: SGD with built-in projection to unit norm sphere\n",
            "sgdw: SGD with decoupled weight decay and Nesterov momentum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the timm factory to pass models directly when creating optimizer.\n",
        "# NOTE: If you pass a model (nn.Module) instead of parameters to the factory it will\n",
        "# auto-create param groups for weight-decay (or layer-decay if enabled).\n",
        "model = nn.Sequential(nn.Linear(1, 16))\n",
        "opt = timm.optim.create_optimizer_v2(model, 'adafactorbv')\n",
        "opt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWO0PlvFzfQf",
        "outputId": "c7300485-d987-4fda-8578-4bc523ab500b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdafactorBigVision (\n",
              "Parameter Group 0\n",
              "    beta2_cap: 0.999\n",
              "    clipping_threshold: None\n",
              "    decay_offset: 0\n",
              "    decay_rate: 0.8\n",
              "    eps: None\n",
              "    foreach: False\n",
              "    lr: 1.0\n",
              "    min_dim_size_to_factor: 32\n",
              "    momentum: 0.9\n",
              "    momentum_dtype: torch.bfloat16\n",
              "    unscaled_wd: False\n",
              "    weight_decay: 0.0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The optimizer classes can be fetched dynamically (based on string) to allow config friendly use without using the factory.\n",
        "opt_class = timm.optim.get_optimizer_class('adoptw')\n",
        "opt_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAfgqPRez5jX",
        "outputId": "22e8dcb4-dbde-44fd-a711-a8301c2ab962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functools.partial(<class 'timm.optim.adopt.Adopt'>, decoupled=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt2 = opt_class(model.parameters())\n",
        "opt2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMzXM1dY0JJA",
        "outputId": "a5900509-a658-4527-bbd3-48ef2d454f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adopt (\n",
              "Parameter Group 0\n",
              "    betas: (0.9, 0.9999)\n",
              "    capturable: False\n",
              "    decoupled: True\n",
              "    differentiable: False\n",
              "    eps: 1e-06\n",
              "    foreach: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0.0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The class function will bind default arguments when optimizer info specifies them, e.g. 'sgd' in `timm` has nesterov enabled by default in factory, that will be bound with the class unless disabled.\n",
        "SgdWithNesterov = timm.optim.get_optimizer_class('sgd')\n",
        "SgdUnbound = timm.optim.get_optimizer_class('sgd', bind_defaults=False)\n",
        "print(SgdWithNesterov)\n",
        "print(SgdUnbound)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDxUdWsJ6FYP",
        "outputId": "7b2f4381-58c9-4679-cc5f-dc39979d2b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "functools.partial(<class 'torch.optim.sgd.SGD'>, nesterov=True)\n",
            "<class 'torch.optim.sgd.SGD'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The information dataclasses that the factory registration uses can be queried, these could be expanded to cover more optimizer traits.\n",
        "opt_info = timm.optim.get_optimizer_info('nadamw')\n",
        "opt_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk9cpwNg0Umd",
        "outputId": "d84ab387-220a-40c8-ebc7-31a8800bfdeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OptimInfo(name='nadamw', opt_class=<class 'timm.optim.nadamw.NAdamW'>, description='Adam with Nesterov momentum and decoupled weight decay', has_eps=True, has_momentum=False, has_betas=True, num_betas=2, second_order=False, defaults=None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer classes can be used directly as with optimizers in `torch.optim`\n",
        "opt3 = timm.optim.NAdamW(model.parameters())\n",
        "opt3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0gQtwvN2XfI",
        "outputId": "b4c84963-0820-4aaa-c6a2-95b95b79dbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NAdamW (\n",
              "Parameter Group 0\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0.01\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}