{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6460700,"sourceType":"datasetVersion","datasetId":841888}],"dockerImageVersionId":30260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import required libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Data Visualization\nimport seaborn as sns #Data Visualization\nfrom pandas.api.types import is_string_dtype #Check Datatype\nfrom pandas.api.types import is_numeric_dtype #Check Datatype\nfrom sklearn.preprocessing import LabelEncoder #preProcessing data\nimport os\n\n# Load Directory\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-30T02:41:52.217683Z","iopub.execute_input":"2022-09-30T02:41:52.218164Z","iopub.status.idle":"2022-09-30T02:41:53.710636Z","shell.execute_reply.started":"2022-09-30T02:41:52.218066Z","shell.execute_reply":"2022-09-30T02:41:53.709299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the Training dataset\ndata=pd.read_csv('../input/customer-segmentation/Train.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:53.714377Z","iopub.execute_input":"2022-09-30T02:41:53.714892Z","iopub.status.idle":"2022-09-30T02:41:53.775879Z","shell.execute_reply.started":"2022-09-30T02:41:53.714849Z","shell.execute_reply":"2022-09-30T02:41:53.774668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# % of missing values\nround(data.isna().sum()/len(data)*100,2)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:53.777557Z","iopub.execute_input":"2022-09-30T02:41:53.778466Z","iopub.status.idle":"2022-09-30T02:41:53.799383Z","shell.execute_reply.started":"2022-09-30T02:41:53.778417Z","shell.execute_reply":"2022-09-30T02:41:53.798353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Study the data\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:53.802901Z","iopub.execute_input":"2022-09-30T02:41:53.803753Z","iopub.status.idle":"2022-09-30T02:41:53.8365Z","shell.execute_reply.started":"2022-09-30T02:41:53.803701Z","shell.execute_reply":"2022-09-30T02:41:53.835137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"as above, we see that data contains some missing values. there are total of 8068 entries, but some columns have less than 8068 entries, which means they have missing values.","metadata":{}},{"cell_type":"code","source":"#data contains 8068 rows and 11 columns.\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:53.838168Z","iopub.execute_input":"2022-09-30T02:41:53.838641Z","iopub.status.idle":"2022-09-30T02:41:53.846922Z","shell.execute_reply.started":"2022-09-30T02:41:53.838593Z","shell.execute_reply":"2022-09-30T02:41:53.84572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:53.848787Z","iopub.execute_input":"2022-09-30T02:41:53.849485Z","iopub.status.idle":"2022-09-30T02:41:53.892304Z","shell.execute_reply.started":"2022-09-30T02:41:53.849434Z","shell.execute_reply":"2022-09-30T02:41:53.890924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Columns 'Work Experience' and 'Family Size' have huge number of null values. Continuous features can be replaced with their mean values. Rest other columns have minimal number of null values, so for now, we will leave them as-is.","metadata":{}},{"cell_type":"code","source":"data.fillna(value={\"Work_Experience\":data[\"Work_Experience\"].mean(), \"Family_Size\":data[\"Family_Size\"].mean(), \"Ever_Married\": data[\"Ever_Married\"].mode()[0], \"Graduated\": data[\"Graduated\"].mode()[0], \"Profession\": data[\"Profession\"].mode()[0]}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:53.894425Z","iopub.execute_input":"2022-09-30T02:41:53.894917Z","iopub.status.idle":"2022-09-30T02:41:53.91234Z","shell.execute_reply.started":"2022-09-30T02:41:53.89487Z","shell.execute_reply":"2022-09-30T02:41:53.910964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop([\"Var_1\",\"ID\"], axis=1, inplace=True)\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:53.914078Z","iopub.execute_input":"2022-09-30T02:41:53.914595Z","iopub.status.idle":"2022-09-30T02:41:53.940705Z","shell.execute_reply.started":"2022-09-30T02:41:53.914544Z","shell.execute_reply":"2022-09-30T02:41:53.939439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Univariate Analysis","metadata":{}},{"cell_type":"code","source":"for col in data.columns:\n    plt.figure(col, figsize=(5,5))\n    plt.title(col)\n    if is_numeric_dtype(data[col]):\n        data[col].plot(kind=\"hist\")\n        plt.show()\n        sns.boxplot(data=data, x=col)\n        \n        \n    if is_string_dtype(data[col]):\n        sns.countplot(x=col, data=data, order=data[col].value_counts().index)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:53.942469Z","iopub.execute_input":"2022-09-30T02:41:53.943043Z","iopub.status.idle":"2022-09-30T02:41:56.092839Z","shell.execute_reply.started":"2022-09-30T02:41:53.943008Z","shell.execute_reply":"2022-09-30T02:41:56.091481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Findings:\n\n* There are more males than females in the dataset\n* There are more married than un-married people\n* Dataset contains more people in age range of 30-50 & data is not normally distributed and has some outliers. Similarly, for experience and family size. where mostly people have 0-4 years of experience & families mainly has 2-4 people\n* There are more graduated people & artist in the dataset\n* People tend to have lower spendings in this dataset.\n* Dataset in balanced across all segments as shown in last graph.\n\nThere are not many outliers, so I would leave them","metadata":{}},{"cell_type":"markdown","source":"# Bi-Variate Analysis\n\n### For numerical variables","metadata":{}},{"cell_type":"code","source":"#Use Pairplot to identify the relationship between numerical-variables\nsns.pairplot(data, vars=['Age','Work_Experience','Family_Size'], diag_kind='hist', palette = \"bright\", hue='Segmentation')","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:41:56.096795Z","iopub.execute_input":"2022-09-30T02:41:56.097183Z","iopub.status.idle":"2022-09-30T02:42:03.957299Z","shell.execute_reply.started":"2022-09-30T02:41:56.097151Z","shell.execute_reply":"2022-09-30T02:42:03.956019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I don't see any kind of relationship between numerical variables.","metadata":{}},{"cell_type":"markdown","source":"### With numerical & categorical variables","metadata":{}},{"cell_type":"code","source":"for ycolumns in ['Age','Work_Experience','Family_Size']:\n    plt.figure(ycolumns, figsize=(5,5))\n    for hcolumns in ['Gender','Profession','Spending_Score', 'Ever_Married']:\n        sns.boxplot(data=data, x=\"Segmentation\", y=ycolumns, hue=hcolumns)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:42:03.95876Z","iopub.execute_input":"2022-09-30T02:42:03.959284Z","iopub.status.idle":"2022-09-30T02:42:12.178681Z","shell.execute_reply.started":"2022-09-30T02:42:03.959233Z","shell.execute_reply":"2022-09-30T02:42:12.177491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age - \nD group has people of lower age group (20-40) while B,C, D have 40-60. A & B have more males than females while D & C both have almost equal number of males and females.\n\nProfession & Age: Lawyers belong to higher age group across all 4 segments. Where in A & B, engineers belong to higher age group with B has more aged engineers than A. \n\nSpending & Age: Across all 4 groups, people with high spending power have wide age distribution. Youngest people with low spending power mainly belongs to segment D. Segment C has less overlapping age groups across different spending score groups.\n\nMarried & Age: Across all age groups, people who are married are older than people who are not married which is obvious. People in group D who are not married and youngest. Group B also has some people who are not married yet & are 45 age. \n\nFemales are significantly more experienced than males in segments D, B however females in groups A, C are slightly higher experienced than males.","metadata":{}},{"cell_type":"markdown","source":"# Feature Scaling\n\nLabelEncoder encode labels with a value between 0 and n_classes-1 where n is the number of distinct labels. Where there is order in values we use LabelEncoder() of sklearn else we use get_dummies() from pandas.","metadata":{}},{"cell_type":"code","source":"data_copy=data.copy()\ndata[\"Spending_Score\"]=LabelEncoder().fit_transform(data[\"Spending_Score\"])\n\nfor columns in [\"Gender\",\"Ever_Married\",\"Graduated\",\"Profession\"]:\n    new_data=pd.get_dummies(data[columns], prefix=columns)\n    data=pd.concat([data,new_data], axis=1)\n    data.drop([columns], axis=1, inplace=True)\n\ndata.drop([\"Gender_Female\",\"Ever_Married_No\",\"Graduated_No\",\"Profession_Marketing\"],axis=1, inplace=True)\nprint(data.head())\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:42:12.181828Z","iopub.execute_input":"2022-09-30T02:42:12.182494Z","iopub.status.idle":"2022-09-30T02:42:12.223881Z","shell.execute_reply.started":"2022-09-30T02:42:12.182453Z","shell.execute_reply":"2022-09-30T02:42:12.222612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Corelation between features","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:42:12.225663Z","iopub.execute_input":"2022-09-30T02:42:12.22605Z","iopub.status.idle":"2022-09-30T02:42:13.537331Z","shell.execute_reply.started":"2022-09-30T02:42:12.226015Z","shell.execute_reply":"2022-09-30T02:42:13.5361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for val in [\"Yes\",\"No\"]:\n    plt.title(val)\n    sns.countplot(x=data_copy[data_copy[\"Ever_Married\"]==val][\"Segmentation\"], hue=data_copy[\"Spending_Score\"])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:42:13.538643Z","iopub.execute_input":"2022-09-30T02:42:13.538989Z","iopub.status.idle":"2022-09-30T02:42:14.005624Z","shell.execute_reply.started":"2022-09-30T02:42:13.53895Z","shell.execute_reply":"2022-09-30T02:42:14.004305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's obvious to see that people who are not married have low spending score and mainly belong to segment D. On the other hand those who are married & have low spending score mainly belongs to group A & D while B & C have more people with average spending score.","metadata":{}},{"cell_type":"code","source":"sns.displot(data=data_copy,x=\"Age\",kde=True, hue=data_copy[\"Ever_Married\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:42:14.007648Z","iopub.execute_input":"2022-09-30T02:42:14.008188Z","iopub.status.idle":"2022-09-30T02:42:14.523706Z","shell.execute_reply.started":"2022-09-30T02:42:14.008137Z","shell.execute_reply":"2022-09-30T02:42:14.522449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling Data - Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Import libraries related to modelling\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\n#define X as set of independent features and y as dependent feature\nX=data.drop(['Segmentation'], axis=1)\ny=data['Segmentation']\n\n#Use Standard Scaler to normalize data on one scale.\nscaler=StandardScaler()\nX=scaler.fit_transform(X)\n\n# Devide dataset into testing (20%) and training (80%)\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2, random_state=42)\n\n#as it is a multiclass problem, so we use LR with parameters relevant for the problem\nKfold_val=KFold(10)\n\n# Initialize Models\nLogReg= LogisticRegression(penalty='l2', max_iter=5000, multi_class='ovr', solver='liblinear')\ndtc=DecisionTreeClassifier(random_state=0)\nrfc=RandomForestClassifier(max_depth=8, random_state=0)\nsvm_c=svm.SVC(kernel='linear', C=1, decision_function_shape='ovo')\nknn=KNeighborsClassifier(n_neighbors=3)\nbnb=BernoulliNB()\nmodels=[LogReg,dtc, rfc, svm_c, knn, bnb ]\nmodels_name={0: 'Logistic Regression',1:'Decision Tree Classification', 2: 'Random Forest Classification', 3:'SVM', 4:'KNN', 5: 'Bernouli Naive'}\n\nmodel_sc={}\ndef model_pred(model, i):\n    model.fit(X_train, y_train)\n    model_predc=model.predict(X_test)\n    model_cv=cross_val_score(model, X, y, cv=Kfold_val)\n    model_cv_sc=np.mean(model_cv)\n    model_sc[models_name[i]]=model_cv_sc\n    print(\"Confusion Matrix for {} is: \\n {}\".format(models_name[i],confusion_matrix(y_test,model_predc)))\n    print(classification_report(y_test,model_predc))\n    print(model_cv)\n    print(np.mean(model_cv))\n    print(\"Accuracy Score is {}\".format(accuracy_score(y_test, model_predc)))\n\n    \nfor i, model_s in enumerate(models):\n    model_pred(model_s, i)\n    \nprint(model_sc)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:47:34.39416Z","iopub.execute_input":"2022-09-30T02:47:34.394652Z","iopub.status.idle":"2022-09-30T02:48:29.938368Z","shell.execute_reply.started":"2022-09-30T02:47:34.394609Z","shell.execute_reply":"2022-09-30T02:48:29.936883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in model_sc:\n    print(x, ':', round(model_sc[x]*100 ))","metadata":{"execution":{"iopub.status.busy":"2022-09-30T02:43:09.157826Z","iopub.execute_input":"2022-09-30T02:43:09.159214Z","iopub.status.idle":"2022-09-30T02:43:09.167139Z","shell.execute_reply.started":"2022-09-30T02:43:09.15916Z","shell.execute_reply":"2022-09-30T02:43:09.165858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nFrom the test results, we can choose Random forest, with 53% accuracy, as our model. It gave us more accurate results since it is an ensemble model. \n\nThanks for reading, I appreciate feedback!\n","metadata":{}}]}