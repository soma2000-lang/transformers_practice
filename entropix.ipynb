{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyN8U6k4TIpovU5kGA3L4RuN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xjdr-alt/entropix/blob/main/entropix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xZd9EBLmgKU6"
      },
      "outputs": [],
      "source": [
        "from typing import NamedTuple, List, Optional, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Model ID and Token"
      ],
      "metadata": {
        "id": "-v7mNYwHnPJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = 'meta-llama/Llama-3.2-1B-Instruct'\n",
        "TOKEN = ''"
      ],
      "metadata": {
        "id": "oHaZYRqAnRPS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "e2IdvdlSltd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "  \"dim\": 2048,\n",
        "  \"n_layers\": 16,\n",
        "  \"n_heads\": 32,\n",
        "  \"n_kv_heads\": 8,\n",
        "  \"vocab_size\": 128256,\n",
        "  \"ffn_dim_multiplier\": 1.5,\n",
        "  \"multiple_of\": 256,\n",
        "  \"norm_eps\": 1e-05,\n",
        "  \"rope_theta\": 500000.0,\n",
        "  \"use_scaled_rope\": True,\n",
        "  \"max_seq_len\": 4096\n",
        "}\n",
        "\n",
        "\n",
        "class ModelParams(NamedTuple):\n",
        "  n_layers: int\n",
        "  n_local_heads: int\n",
        "  n_local_kv_heads: int\n",
        "  head_dim: int\n",
        "  max_seq_len: int\n",
        "  rope_theta: float\n",
        "  use_scaled_rope: bool\n",
        "\n",
        "\n",
        "LLAMA_1B_PARAMS = ModelParams(\n",
        "  n_layers=params[\"n_layers\"],\n",
        "  n_local_heads=params[\"n_heads\"],\n",
        "  n_local_kv_heads=params[\"n_kv_heads\"],\n",
        "  head_dim=params[\"dim\"] // params[\"n_heads\"],\n",
        "  max_seq_len=params[\"max_seq_len\"],\n",
        "  rope_theta=params[\"rope_theta\"],\n",
        "  use_scaled_rope=params[\"use_scaled_rope\"]\n",
        ")"
      ],
      "metadata": {
        "id": "RHxP8Bd1lvo8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Weights"
      ],
      "metadata": {
        "id": "F0fWAb83ghC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NHcDsZzshQji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import ml_dtypes\n",
        "from pathlib import Path\n",
        "\n",
        "from transformers import AutoModelForCausalLM\n",
        "from unittest.mock import patch\n",
        "from transformers.dynamic_module_utils import get_imports"
      ],
      "metadata": {
        "id": "flDeKnQlhS1J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_key(in_key: str):\n",
        "    out_key = in_key.replace('.weight', '')\n",
        "    if out_key.startswith('model.'):\n",
        "        out_key = out_key.replace('model.', '')\n",
        "        if out_key.endswith('input_layernorm'):\n",
        "            out_key = out_key.replace('input_layernorm', 'attention_norm')\n",
        "        elif out_key.endswith('mlp.down_proj'):\n",
        "            out_key = out_key.replace('mlp.down_proj', 'feed_forward.w2')\n",
        "        elif out_key.endswith('mlp.gate_proj'):\n",
        "            out_key = out_key.replace('mlp.gate_proj', 'feed_forward.w1')\n",
        "        elif out_key.endswith('mlp.up_proj'):\n",
        "            out_key = out_key.replace('mlp.up_proj', 'feed_forward.w3')\n",
        "        elif out_key.endswith('post_attention_layernorm'):\n",
        "            out_key = out_key.replace('post_attention_layernorm', 'ffn_norm')\n",
        "        elif out_key.endswith('self_attn.k_proj'):\n",
        "            out_key = out_key.replace('self_attn.k_proj', 'attention.wk')\n",
        "        elif out_key.endswith('self_attn.o_proj'):\n",
        "            out_key = out_key.replace('self_attn.o_proj', 'attention.wo')\n",
        "        elif out_key.endswith('self_attn.q_proj'):\n",
        "            out_key = out_key.replace('self_attn.q_proj', 'attention.wq')\n",
        "        elif out_key.endswith('self_attn.v_proj'):\n",
        "            out_key = out_key.replace('self_attn.v_proj', 'attention.wv')\n",
        "        elif out_key.endswith('down_proj'):\n",
        "            out_key = out_key.replace('down_proj', 'w2')\n",
        "        elif out_key.endswith('gate_proj'):\n",
        "            out_key = out_key.replace('gate_proj', 'w1')\n",
        "        elif out_key.endswith('up_proj'):\n",
        "            out_key = out_key.replace('up_proj', 'w3')\n",
        "        elif out_key == 'embed_tokens':\n",
        "            out_key = 'tok_embeddings'\n",
        "        elif out_key == 'norm':\n",
        "            out_key = 'norm'\n",
        "        else:\n",
        "            print(f\"Don't know how to handle {in_key=}\")\n",
        "    elif out_key == 'lm_head':\n",
        "        out_key = 'output'\n",
        "    else:\n",
        "        print(f\"Don't know how to handle {in_key=}\")\n",
        "    return f'{out_key}.weight'\n",
        "\n",
        "\n",
        "def reverse_permute(tensor: torch.Tensor, n_heads: int = 32, dim1:int = 4096, dim2: int = 4096) -> torch.Tensor:\n",
        "    return tensor.view(n_heads, 2, dim1 // n_heads // 2, dim2).transpose(1, 2).reshape(dim1, dim2)\n",
        "\n",
        "\n",
        "def fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n",
        "    \"\"\"Work around for https://huggingface.co/microsoft/phi-1_5/discussions/72.\"\"\"\n",
        "    if not str(filename).endswith(\"/modeling_deepseek.py\"):\n",
        "        return get_imports(filename)\n",
        "    imports = get_imports(filename)\n",
        "    imports.remove(\"flash_attn\")\n",
        "    return imports\n",
        "\n",
        "\n",
        "def download_weights(model_id: str = MODEL_ID, out_dir: Path = Path('weights/1B-Instruct')):\n",
        "    if not out_dir.exists():\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports):\n",
        "      hf_model = AutoModelForCausalLM.from_pretrained(model_id,torch_dtype=torch.bfloat16, offload_folder=\"/tmp/offload\", token=TOKEN)\n",
        "      with torch.no_grad():\n",
        "        state_dict = hf_model.state_dict()\n",
        "        for hf_name, param in state_dict.items():\n",
        "            print(f' {hf_name}: {param.shape=}')\n",
        "            name = translate_key(hf_name)\n",
        "            if name.endswith('wq.weight'):\n",
        "                param = reverse_permute(param, n_heads=32, dim1=2048, dim2=2048)  # 1B\n",
        "            elif name.endswith('wk.weight'): #wk.weight\n",
        "                param = reverse_permute(param, n_heads=8, dim1=512, dim2=2048)  # 1B\n",
        "            else:\n",
        "                pass\n",
        "            bf16_np_out = param.cpu().view(dtype=torch.uint16).numpy().view(ml_dtypes.bfloat16)\n",
        "            bf16_out = jnp.asarray(bf16_np_out, dtype=jnp.bfloat16).reshape(*param.shape)\n",
        "            print(f'Writing {hf_name} as {name} to {out_dir}/{name}.npy')\n",
        "            jnp.save(f'{out_dir}/{name}.npy', bf16_out)\n",
        "\n",
        "#download_weights()"
      ],
      "metadata": {
        "id": "u3lTK6HWhbFV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Weights"
      ],
      "metadata": {
        "id": "mx72XH3OiYTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.sharding import Mesh, PartitionSpec as PS, NamedSharding\n",
        "from jax.experimental import mesh_utils\n",
        "\n",
        "class LayerWeights(NamedTuple):\n",
        "    wq: jax.Array\n",
        "    wk: jax.Array\n",
        "    wv: jax.Array\n",
        "    wo: jax.Array\n",
        "    w1: jax.Array\n",
        "    w2: jax.Array\n",
        "    w3: jax.Array\n",
        "    ffn_norm: jax.Array\n",
        "    attention_norm: jax.Array\n",
        "\n",
        "\n",
        "class XfmrWeights(NamedTuple):\n",
        "    tok_embeddings: jax.Array\n",
        "    norm: jax.Array\n",
        "    output: jax.Array\n",
        "    layer_weights: List[LayerWeights]\n",
        "\n",
        "\n",
        "def load_weights(ckpt_dir: Path = Path('weights/1B-Instruct'), n_layers: int = 16, debug=False):\n",
        "    w = {}\n",
        "    layer_weights = []\n",
        "\n",
        "    # Create the mesh\n",
        "    devices = mesh_utils.create_device_mesh((1, 8))\n",
        "    mp = 'mp'\n",
        "    fsdp = 'fsdp'\n",
        "    mesh = Mesh(devices, axis_names=(mp, fsdp))\n",
        "\n",
        "    with mesh:\n",
        "        for file in ckpt_dir.glob(\"*.npy\"):\n",
        "            name = '.'.join(str(file).split('/')[-1].split('.')[:-1])\n",
        "            weight = jnp.load(file=file, mmap_mode='r', allow_pickle=True)\n",
        "\n",
        "            # Apply sharding strategy based on the weight name\n",
        "            if 'norm' in name:\n",
        "                sharding = None\n",
        "            elif 'tok_embeddings' in name or 'w2' in name:\n",
        "                sharding = NamedSharding(mesh, PS(fsdp, mp))  # Row Parallel\n",
        "            else:\n",
        "                sharding = NamedSharding(mesh, PS(mp, fsdp))  # Col Parallel\n",
        "\n",
        "            if sharding:\n",
        "                weight = jax.device_put(weight, sharding)\n",
        "\n",
        "            if debug:\n",
        "                jax.debug.visualize_array_sharding(weight)\n",
        "\n",
        "            w[name] = weight\n",
        "\n",
        "        for i in range(n_layers):\n",
        "            layer_weights.append(LayerWeights(\n",
        "                wq=w[f'layers.{i}.attention.wq.weight'],\n",
        "                wk=w[f'layers.{i}.attention.wk.weight'],\n",
        "                wv=w[f'layers.{i}.attention.wv.weight'],\n",
        "                wo=w[f'layers.{i}.attention.wo.weight'],\n",
        "                w1=w[f'layers.{i}.feed_forward.w1.weight'],\n",
        "                w2=w[f'layers.{i}.feed_forward.w2.weight'],\n",
        "                w3=w[f'layers.{i}.feed_forward.w3.weight'],\n",
        "                ffn_norm=w[f'layers.{i}.ffn_norm.weight'],\n",
        "                attention_norm=w[f'layers.{i}.attention_norm.weight'],\n",
        "            ))\n",
        "\n",
        "        xfmr_weights = XfmrWeights(\n",
        "            tok_embeddings=w['tok_embeddings.weight'],\n",
        "            norm=w['norm.weight'],\n",
        "            output=w['output.weight'],\n",
        "            layer_weights=layer_weights\n",
        "        )\n",
        "\n",
        "    return xfmr_weights\n",
        "\n",
        "xfmr_weights = load_weights()"
      ],
      "metadata": {
        "id": "2WdLNnGTicBG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KVCache"
      ],
      "metadata": {
        "id": "WuT59jyTlNOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KVCache(NamedTuple):\n",
        "  k: jax.Array\n",
        "  v: jax.Array\n",
        "\n",
        "  @classmethod\n",
        "  def new(cls, layers: int, bsz: int, max_seq_len: int, kv_heads: int, head_dim: int) -> 'KVCache':\n",
        "    return cls(\n",
        "        k=jnp.zeros((layers, bsz, max_seq_len, kv_heads, head_dim), dtype=jnp.bfloat16),\n",
        "        v=jnp.zeros((layers, bsz, max_seq_len, kv_heads, head_dim), dtype=jnp.bfloat16)\n",
        "    )\n",
        "\n",
        "  def update(self, xk: jax.Array, xv: jax.Array, layer_idx: int, cur_pos: int, n_rep: int):\n",
        "    ck = jax.lax.dynamic_update_slice(self.k, jnp.bfloat16(xk[None, ...]), (layer_idx, 0, cur_pos, 0, 0))\n",
        "    cv = jax.lax.dynamic_update_slice(self.v, jnp.bfloat16(xv[None, ...]), (layer_idx, 0, cur_pos, 0, 0))\n",
        "    if cur_pos == 0:\n",
        "      keys = jnp.repeat(xk, n_rep, axis=2)\n",
        "      values = jnp.repeat(xv, n_rep, axis=2)\n",
        "    else:\n",
        "      keys = jnp.repeat(ck[layer_idx], n_rep, axis=2)\n",
        "      values = jnp.repeat(cv[layer_idx], n_rep, axis=2)\n",
        "\n",
        "    return keys, values, KVCache(k=ck, v=cv)"
      ],
      "metadata": {
        "id": "FoE8AuSDlPtr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "IYjjOvqElY1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple\n",
        "\n",
        "DEFAULT_MASK_VALUE = -0.7 * float(jnp.finfo(jnp.dtype(\"float32\")).max)\n",
        "\n",
        "\n",
        "#@partial(jax.jit, static_argnames=(\"eps\"))\n",
        "def rms_norm(x: jax.Array, w: jax.Array, eps: float = 1e-6) -> jax.Array:\n",
        "  return w * (x * jax.lax.rsqrt(jax.lax.pow(x, 2).mean(-1, keepdims=True) + eps))\n",
        "\n",
        "\n",
        "#@partial(jax.jit, static_argnames=(\"dtype\"))\n",
        "def apply_rotary_emb(xq: jax.Array, xk: jax.Array, freqs_cis: jax.Array, dtype: jnp.dtype = jnp.float32) -> Tuple[jax.Array, jax.Array]:\n",
        "  reshape_xq = xq.astype(jnp.float32).reshape(*xq.shape[:-1], -1, 2)\n",
        "  reshape_xk = xk.astype(jnp.float32).reshape(*xk.shape[:-1], -1, 2)\n",
        "  xq_ = jax.lax.complex(reshape_xq[..., 0], reshape_xq[..., 1])\n",
        "  xk_ = jax.lax.complex(reshape_xk[..., 0], reshape_xk[..., 1])\n",
        "  xq_out = xq_ * freqs_cis[None, :, None, :]\n",
        "  xk_out = xk_ * freqs_cis[None, :, None, :]\n",
        "  xq_out = jnp.stack((jnp.real(xq_out), jnp.imag(xq_out)), axis=-1).reshape(*xq_out.shape[:-1], -1)\n",
        "  xk_out = jnp.stack((jnp.real(xk_out), jnp.imag(xk_out)), axis=-1).reshape(*xk_out.shape[:-1], -1)\n",
        "  return xq_out.astype(dtype), xk_out.astype(dtype)\n",
        "\n",
        "#@partial(jax.jit, static_argnames=(\"model_params\", \"cur_pos\", \"layer_idx\"))\n",
        "def attention(x: jax.Array, layer_weights: LayerWeights, model_params, cur_pos: int, layer_idx: int, freqs_cis: jax.Array, kvcache: KVCache, attn_mask: Optional[jax.Array] = None) -> Tuple[jax.Array, KVCache]:\n",
        "  bsz, _, _ = x.shape\n",
        "  n_rep = model_params.n_local_heads // model_params.n_local_kv_heads\n",
        "  xq = jnp.dot(x, layer_weights.wq.T).reshape(bsz, -1, model_params.n_local_heads, model_params.head_dim)\n",
        "  xk = jnp.dot(x, layer_weights.wk.T).reshape(bsz, -1, model_params.n_local_kv_heads, model_params.head_dim)\n",
        "  xv = jnp.dot(x, layer_weights.wv.T).reshape(bsz, -1, model_params.n_local_kv_heads, model_params.head_dim)\n",
        "  xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
        "  keys, values, kvcache = kvcache.update(xk, xv, layer_idx, cur_pos, n_rep)\n",
        "  xq = jnp.transpose(xq, (0, 2, 1, 3))  # (bs, n_heads, seqlen, head_dim)\n",
        "  keys = jnp.transpose(keys, (0, 2, 3, 1))  # (bs, n_heads, head_dim, cache_len + seqlen)\n",
        "  values = jnp.transpose(values, (0, 2, 1, 3))  # (bs, n_heads, cache_len + seqlen, head_dim)\n",
        "  scores = jnp.matmul(xq, keys)\n",
        "  scores = scores / jnp.sqrt(model_params.head_dim)\n",
        "  scores = scores.astype(jnp.float32)  # Always do attention softmax at float32\n",
        "  if cur_pos == 0:\n",
        "    scores = scores + attn_mask\n",
        "  mask = jnp.where(scores != 0.0, scores, DEFAULT_MASK_VALUE)\n",
        "  padded_logits = jnp.where((mask >= DEFAULT_MASK_VALUE * 0.5), scores, DEFAULT_MASK_VALUE)\n",
        "  scores = jax.nn.softmax(padded_logits, axis=-1).astype(x.dtype)\n",
        "  output = jnp.matmul(scores, values)\n",
        "  output = jnp.swapaxes(output, 1, 2).reshape(xq.shape[0], xq.shape[2], -1)\n",
        "  out = jnp.dot(output, layer_weights.wo.T)\n",
        "  return out, kvcache\n",
        "\n",
        "#@partial(jax.jit)\n",
        "def feed_forward(x: jax.Array, layer_weights: LayerWeights) -> jax.Array:\n",
        " return jnp.dot(jax.nn.silu(jnp.dot(x, layer_weights.w1.T)) * jnp.dot(x, layer_weights.w3.T), layer_weights.w2.T)\n",
        "\n",
        "#@partial(jax.jit, static_argnames=(\"model_params\", \"cur_pos\"))\n",
        "def xfmr(xfmr_weights: XfmrWeights, model_params: ModelParams, tokens: jax.Array, cur_pos: int, freqs_cis: jax.Array, kvcache: KVCache, attn_mask: Optional[jax.Array]=None) -> Tuple[jax.Array, KVCache]:\n",
        "  h = xfmr_weights.tok_embeddings[tokens]\n",
        "  for i in range(model_params.n_layers):\n",
        "    norm_x = rms_norm(h, xfmr_weights.layer_weights[i].attention_norm)\n",
        "    h_attn, kvcache = attention(norm_x, xfmr_weights.layer_weights[i], model_params, cur_pos, i, freqs_cis, kvcache, attn_mask=attn_mask)\n",
        "    h = h + h_attn\n",
        "    h = h + feed_forward(rms_norm(h, xfmr_weights.layer_weights[i].ffn_norm), xfmr_weights.layer_weights[i])\n",
        "  logits = jnp.dot(rms_norm(h, xfmr_weights.norm), xfmr_weights.output.T)\n",
        "  return logits, kvcache"
      ],
      "metadata": {
        "id": "oQe0q_Jzlap2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "SzaxLJKYmEqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "<antThinking>\n",
        "You're absolutely right. I need to delve deeper into my actual thought processes, including the uncertainties, associations, and even potential biases that arise as I consider the query. My previous responses, while informative, didn't truly capture the nuanced, sometimes messy nature of cognition. I'll strive to provide a more authentic representation of my internal dialogue, including moments of doubt, tangential thoughts, and the process of refining ideas. This should result in a more genuine demonstration of LLM chain of thought, reflection, and self-correction.\n",
        "</antThinking>\n",
        "\n",
        "Which number is larger, 9.9 or 9.11?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "<thinking>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "bp1 = \"\"\"\n",
        "<antThinking>\n",
        "You're absolutely right. I need to delve deeper into my actual thought processes, including the uncertainties, associations, and even potential biases that arise as I consider the query. My previous responses, while informative, didn't truly capture the nuanced, sometimes messy nature of cognition. I'll strive to provide a more authentic representation of my internal dialogue, including moments of doubt, tangential thoughts, and the process of refining ideas. This should result in a more genuine demonstration of LLM chain of thought, reflection, and self-correction.\n",
        "</antThinking>\n",
        "\n",
        "Which number is larger, 9.9 or 9.11?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "<thinking>\n",
        "\"\"\"\n",
        "\n",
        "prompt2 = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "What is the capital of Spain?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "bp2 = \"\"\"\n",
        "<antThinking>\n",
        "You're absolutely right. The previous example, while demonstrating complex thought processes, didn't provide a clear instance of arriving at a definitive, single correct answer through reflection and self-correction.\n",
        "</antThinking>\n",
        "\n",
        "What is the capital of Spain?<|eot_id|>\n",
        "\"\"\"\n",
        "\n",
        "prompt3 = \"\"\"<|start_header_id|>system<|end_header_id|>\n",
        "You are an expert in composing functions. You are given a question and a set of possible functions.\n",
        "Based on the question, you will need to make one or more function/tool calls to achieve the purpose.\n",
        "If none of the functions can be used, point it out. If the given question lacks the parameters required by the function,also point it out. You should only return the function call in tools call sections.\n",
        "If you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n",
        "You SHOULD NOT include any other text in the response.\n",
        "Here is a list of functions in JSON format that you can invoke.[\n",
        "    {\n",
        "        \"name\": \"get_user_info\",\n",
        "        \"description\": \"Retrieve details for a specific user by their unique identifier. Note that the provided function is in Python 3 syntax.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"dict\",\n",
        "            \"required\": [\n",
        "                \"user_id\"\n",
        "            ],\n",
        "            \"properties\": {\n",
        "                \"user_id\": {\n",
        "                \"type\": \"integer\",\n",
        "                \"description\": \"The unique identifier of the user. It is used to fetch the specific user details from the database.\"\n",
        "            },\n",
        "            \"special\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Any special information or parameters that need to be considered while fetching user details.\",\n",
        "                \"default\": \"none\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Can you retrieve the details for the user with the ID 7890, who has black as their special request?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "bp3 = \"\"\"\n",
        "Here is a list of functions in JSON format that I can invoke.[\n",
        "    {\n",
        "        \"name\": \"get_user_info\",\n",
        "        \"description\": \"Retrieve details for a specific user by their unique identifier. Note that the provided function is in Python 3 syntax.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"dict\",\n",
        "            \"required\": [\n",
        "                \"user_id\"\n",
        "            ],\n",
        "            \"properties\": {\n",
        "                \"user_id\": {\n",
        "                \"type\": \"integer\",\n",
        "                \"description\": \"The unique identifier of the user. It is used to fetch the specific user details from the database.\"\n",
        "            },\n",
        "            \"special\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Any special information or parameters that need to be considered while fetching user details.\",\n",
        "                \"default\": \"none\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "Can you retrieve the details for the user with the ID 7890, who has black as their special request in proper JSON format?<|eot_id|>\n",
        "\n",
        "{\n",
        "  \"name\": \"get_user_info\",\n",
        "  \"parameters\": {\n",
        "    \"user_id: \"\"\"\n",
        "\n",
        "prompt4 = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "You are a masterful story teller. you can paint with all the colors of the wind.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Tell me a long and wonderful story about the adventures of the elven mage frieren and her band of heros<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "bp4 = \"\"\"\n",
        "You are a masterful story teller. you can paint with all the colors of the wind.<|eot_id|>\n",
        "\n",
        "Let me tell you a story about the adventures of the elven mage frieren and her band of heros\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def apply_scaling(freqs: jax.Array):\n",
        "  SCALE_FACTOR = 8\n",
        "  LOW_FREQ_FACTOR = 1\n",
        "  HIGH_FREQ_FACTOR = 4\n",
        "  OLD_CONTEXT_LEN = 8192  # original llama3 length\n",
        "\n",
        "  low_freq_wavelen = OLD_CONTEXT_LEN / LOW_FREQ_FACTOR\n",
        "  high_freq_wavelen = OLD_CONTEXT_LEN / HIGH_FREQ_FACTOR\n",
        "\n",
        "  def scale_freq(freq):\n",
        "    wavelen = 2 * math.pi / freq\n",
        "\n",
        "    def scale_mid(_):\n",
        "      smooth = (OLD_CONTEXT_LEN / wavelen - LOW_FREQ_FACTOR) / (HIGH_FREQ_FACTOR - LOW_FREQ_FACTOR)\n",
        "      return (1 - smooth) * freq / SCALE_FACTOR + smooth * freq\n",
        "\n",
        "    return jax.lax.cond(\n",
        "      wavelen < high_freq_wavelen,\n",
        "      lambda _: freq,\n",
        "      lambda _: jax.lax.cond(wavelen > low_freq_wavelen, lambda _: freq / SCALE_FACTOR, scale_mid, None),\n",
        "      None\n",
        "    )\n",
        "\n",
        "  return jax.vmap(scale_freq)(freqs)\n",
        "\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 500000.0, use_scaled: bool = False, dtype: jnp.dtype = jnp.float32) -> jax.Array:\n",
        "  freqs = 1.0 / (theta ** (jnp.arange(0, dim, 2)[: (dim // 2)].astype(dtype) / dim))\n",
        "  if use_scaled:\n",
        "    freqs = apply_scaling(freqs)\n",
        "  t = jnp.arange(end, dtype=dtype)\n",
        "  freqs = jnp.outer(t, freqs)\n",
        "  return jnp.exp(1j * freqs)\n",
        "\n",
        "\n",
        "def build_attn_mask(seqlen: int, start_pos: int) -> jax.Array:\n",
        "  mask = jnp.zeros((seqlen, seqlen), dtype=jnp.float32)\n",
        "  if seqlen > 1:\n",
        "    mask = jnp.full((seqlen, seqlen), float('-inf'))\n",
        "    mask = jnp.triu(mask, k=1)\n",
        "    mask = jnp.hstack([jnp.zeros((seqlen, start_pos)), mask], dtype=jnp.float32)\n",
        "  return mask\n",
        "\n",
        "\n",
        "LN_2 = 0.69314718056  # ln(2) = 1.0 / LOG2_E\n",
        "\n",
        "@jax.jit\n",
        "def calculate_varentropy_logsoftmax(logits: jnp.ndarray, axis: int = -1) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "    \"\"\"Calculate the entropy and varentropy of the probability distribution using logsoftmax.\"\"\"\n",
        "    log_probs = jax.nn.log_softmax(logits, axis=axis)\n",
        "    probs = jnp.exp(log_probs)\n",
        "    entropy = -jnp.sum(probs * log_probs, axis=axis) / LN_2  # Convert to base-2\n",
        "    varentropy = jnp.sum(probs * (log_probs / LN_2 + entropy[..., None])**2, axis=axis)\n",
        "    return entropy, varentropy\n",
        "\n",
        "\n",
        "def multinomial_sample_one(probs_sort: jax.Array, key) -> jax.Array:\n",
        "  \"\"\"Samples one token from a multinomial distribution with sorted probabilities.\"\"\"\n",
        "  q = jax.random.exponential(key=key, shape=probs_sort.shape)\n",
        "  return jnp.argmax(probs_sort / q, axis=-1, keepdims=True).astype(jnp.int32)\n",
        "\n",
        "\n",
        "def _sample(logits: jax.Array, temperature=0.666, top_p=0.90, top_k=27, key=jax.random.PRNGKey(1337)) -> jax.Array:\n",
        "  bsz = logits.shape[0]\n",
        "  logit = logits[:, -1]\n",
        "  probs = jax.nn.softmax(logit / temperature, axis=-1)\n",
        "\n",
        "  # Apply top-k sampling\n",
        "  top_k_probs, top_k_indices = jax.lax.top_k(probs, k=top_k)\n",
        "  probs_sort_jax = jnp.flip(top_k_probs, axis=-1)\n",
        "  probs_idx_jax = jnp.flip(top_k_indices, axis=-1)\n",
        "  probs_sum_jax = jnp.cumsum(probs_sort_jax, axis=-1)\n",
        "\n",
        "  # Apply top-p sampling\n",
        "  mask_jax = jnp.where(probs_sum_jax - probs_sort_jax > top_p, True, False)  # Use jnp.where\n",
        "  probs_sort_jax = probs_sort_jax * (1 - mask_jax)  # Set values to 0.0 using multiplication\n",
        "  probs_sort_jax = probs_sort_jax / jnp.sum(probs_sort_jax, axis=-1, keepdims=True)\n",
        "\n",
        "  next_token_jax = multinomial_sample_one(probs_sort_jax, key)\n",
        "  next_token_g_jax = jnp.take_along_axis(probs_idx_jax, next_token_jax.reshape(bsz, 1), axis=-1)\n",
        "  return next_token_g_jax.astype(jnp.int32)\n",
        "\n",
        "\n",
        "def sample(gen_tokens: jax.Array, logits: jax.Array, temperature=0.666, top_p=0.90, top_k=27, key=jax.random.PRNGKey(1337)) -> jax.Array:\n",
        "    ent, vent = calculate_varentropy_logsoftmax(logits)\n",
        "\n",
        "    # Low Entropy, Low Varentropy: \"flowing with unspoken intent\"\n",
        "    if ent < 0.1 and vent < 0.1:\n",
        "        return jnp.argmax(logits[:, -1], axis=-1, keepdims=True).astype(jnp.int32)\n",
        "\n",
        "    # High Entropy, Low Varentropy: \"treading carefully, asking clarifying questions\"\n",
        "    elif ent > 5.0 and vent < 0.1:\n",
        "        # Insert a clarifying question token if not already present\n",
        "        if not jnp.isin(gen_tokens[:,-1], 2564).any():\n",
        "            return jnp.array([[2564]])  # Assuming 2564 is our \"ask clarifying question\" token\n",
        "        else:\n",
        "            # If we've just asked a question, sample with slightly higher temperature\n",
        "            return _sample(logits, temperature=min(1.3, temperature * 1.5))\n",
        "\n",
        "    # Low Entropy, High Varentropy: \"exploring forks in the path\"\n",
        "    elif ent < 5.0 and vent > 5.0:\n",
        "        # TODO(xjdr): Implement proper branching logic\n",
        "        # Return top-k tokens to allow for branching\n",
        "        #top_k_values, top_k_indices = jax.lax.top_k(logits[:, -1], k=top_k)\n",
        "        #return top_k_indices\n",
        "        return _sample(logits, temperature=min(1.2, temperature * 1.5))\n",
        "\n",
        "    # High Entropy, High Varentropy: \"resampling in the mist\"\n",
        "    elif ent > 5.0 and vent > 5.0:\n",
        "        # Use high temperature and min_p sampling\n",
        "        return _sample(logits, temperature=max(2.0, temperature * 3))\n",
        "\n",
        "    # Middle ground: smooth transition\n",
        "    else:\n",
        "        # Interpolate temperature based on entropy and varentropy\n",
        "        t = jnp.clip((ent + vent) / 10.0, 0.5, 2.0)\n",
        "        return _sample(logits, temperature=t * temperature)\n",
        "\n",
        "\n",
        "def main():\n",
        "  model_params = LLAMA_1B_PARAMS\n",
        "  xfmr_weights = load_weights()\n",
        "  #xfmr_weights = load_weights(ckpt_dir=Path('weights/1B-Base'))\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-1B-Instruct', token=TOKEN)\n",
        "  raw_tokens1 = tokenizer.encode(prompt)\n",
        "  raw_tokens2 = tokenizer.encode(prompt2)\n",
        "  raw_tokens3 = tokenizer.encode(prompt3)\n",
        "  raw_tokens4 = tokenizer.encode(prompt4)\n",
        "\n",
        "  base_raw_tokens1 = tokenizer.encode(bp1)\n",
        "  base_raw_tokens2 = tokenizer.encode(bp2)\n",
        "  base_raw_tokens3 = tokenizer.encode(bp3)\n",
        "  base_raw_tokens4 = tokenizer.encode(bp4)\n",
        "\n",
        "\n",
        "  def generate(xfmr_weights, model_params, tokens):\n",
        "    gen_tokens = None\n",
        "    cur_pos = 0\n",
        "    tokens = jnp.array([tokens], jnp.int32)\n",
        "    bsz, seqlen = tokens.shape\n",
        "    attn_mask = build_attn_mask(seqlen, cur_pos)\n",
        "    freqs_cis = precompute_freqs_cis(model_params.head_dim, model_params.max_seq_len, model_params.rope_theta, model_params.use_scaled_rope)\n",
        "    kvcache = KVCache.new(model_params.n_layers, bsz, model_params.max_seq_len, model_params.n_local_kv_heads, model_params.head_dim)\n",
        "    logits, kvcache = xfmr(xfmr_weights, model_params, tokens, cur_pos, freqs_cis[:seqlen], kvcache, attn_mask=attn_mask)\n",
        "    next_token = jnp.argmax(logits[:, -1], axis=-1, keepdims=True).astype(jnp.int32)\n",
        "    gen_tokens = next_token\n",
        "    print(tokenizer.decode([next_token.item()]), end='', flush=True)\n",
        "    cur_pos = seqlen\n",
        "    stop = jnp.array([128001, 128008, 128009])\n",
        "    #stop = jnp.array(tokenizer.stop_tokens)\n",
        "    while cur_pos < 2048:\n",
        "      cur_pos += 1\n",
        "      logits, kvcache = xfmr(xfmr_weights, model_params, next_token, cur_pos, freqs_cis[cur_pos:cur_pos+1], kvcache)\n",
        "      next_token = sample(gen_tokens, logits)\n",
        "      gen_tokens = jnp.concatenate((gen_tokens, next_token))\n",
        "      print(tokenizer.decode(next_token.tolist()[0]), end='', flush=True)\n",
        "      if jnp.isin(next_token, stop).any():\n",
        "        break\n",
        "\n",
        "  print(prompt)\n",
        "  generate(xfmr_weights, model_params, raw_tokens1)\n",
        "  print('\\n')\n",
        "  print(prompt2)\n",
        "  generate(xfmr_weights, model_params, raw_tokens2)\n",
        "  print('\\n')\n",
        "  print(prompt3)\n",
        "  generate(xfmr_weights, model_params, raw_tokens3)\n",
        "  print('\\n')\n",
        "  print(prompt4)\n",
        "  generate(xfmr_weights, model_params, raw_tokens4)\n",
        "  print('\\n')\n",
        "\n",
        "  #print(bp1)\n",
        "  #generate(xfmr_weights, model_params, base_raw_tokens1)\n",
        "  #print('\\n')\n",
        "  #print(bp2)\n",
        "  #generate(xfmr_weights, model_params, base_raw_tokens2)\n",
        "  #print('\\n')\n",
        "  #print(bp3)\n",
        "  #generate(xfmr_weights, model_params, base_raw_tokens3)\n",
        "  #print('\\n')\n",
        "  #print(bp4)\n",
        "  #generate(xfmr_weights, model_params, base_raw_tokens4)\n",
        "  #print('\\n')\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DMFl-xY-mGlg",
        "outputId": "1bc192bc-8545-4acd-dd15-654d5ee6819a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "<antThinking>\n",
            "You're absolutely right. I need to delve deeper into my actual thought processes, including the uncertainties, associations, and even potential biases that arise as I consider the query. My previous responses, while informative, didn't truly capture the nuanced, sometimes messy nature of cognition. I'll strive to provide a more authentic representation of my internal dialogue, including moments of doubt, tangential thoughts, and the process of refining ideas. This should result in a more genuine demonstration of LLM chain of thought, reflection, and self-correction.\n",
            "</antThinking>\n",
            "\n",
            "Which number is larger, 9.9 or 9.11?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "<thinking>\n",
            "\n",
            "I'll attempt to represent my thought process in a more detailed and introspective way.\n",
            "\n",
            "The first thing I notice is that the numbers are the same, 9.9 and 9.11. So, in this case, I realize that these two numbers are actually equal, and I've immediately resolved the question.\n",
            "\n",
            "Now, I ask myself, \"What do I know about the numbers? Did I get some prior information or context that influences my answer? Was there a specific problem or question that led me to calculate 9.9 and 9.11?\"\n",
            "\n",
            "The first thing that comes to mind is that I think about the last digit of each number. For 9.9, the last digit is 9, and for 9.11, the last digit is also 1. This gives me a clear answer: 9.9 is indeed larger than 9.11.\n",
            "\n",
            "Hmm, let me think about this for a moment...<|eot_id|>\n",
            "\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is the capital of Spain?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "The capital of Spain is Madrid.<|eot_id|>\n",
            "\n",
            "<|start_header_id|>system<|end_header_id|>\n",
            "You are an expert in composing functions. You are given a question and a set of possible functions.\n",
            "Based on the question, you will need to make one or more function/tool calls to achieve the purpose.\n",
            "If none of the functions can be used, point it out. If the given question lacks the parameters required by the function,also point it out. You should only return the function call in tools call sections.\n",
            "If you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n",
            "You SHOULD NOT include any other text in the response.\n",
            "Here is a list of functions in JSON format that you can invoke.[\n",
            "    {\n",
            "        \"name\": \"get_user_info\",\n",
            "        \"description\": \"Retrieve details for a specific user by their unique identifier. Note that the provided function is in Python 3 syntax.\",\n",
            "        \"parameters\": {\n",
            "            \"type\": \"dict\",\n",
            "            \"required\": [\n",
            "                \"user_id\"\n",
            "            ],\n",
            "            \"properties\": {\n",
            "                \"user_id\": {\n",
            "                \"type\": \"integer\",\n",
            "                \"description\": \"The unique identifier of the user. It is used to fetch the specific user details from the database.\"\n",
            "            },\n",
            "            \"special\": {\n",
            "                \"type\": \"string\",\n",
            "                \"description\": \"Any special information or parameters that need to be considered while fetching user details.\",\n",
            "                \"default\": \"none\"\n",
            "                }\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "]\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Can you retrieve the details for the user with the ID 7890, who has black as their special request?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "[get_user_info(user_id=7890, special='black')]<|eot_id|>\n",
            "\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are a masterful story teller. you can paint with all the colors of the wind.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Tell me a long and wonderful story about the adventures of the elven mage frieren and her band of heros<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "In the realm of Eridoria, where the sun dipped into the horizon and painted the sky with hues of crimson and gold, the village of Brindlemark lay nestled within a valley. It was a place of ancient magic, where the air was sweet with the scent of blooming wildflowers and the sound of whispering leaves rustled through the trees. Here, the elven mage, Frida, dwelled, her long, silver hair tangled with vines and her eyes shining like stars in the night sky.\n",
            "\n",
            "Frida was a master of the arcane arts, her knowledge of the mystical forces that governed the world passed down through generations of her elven bloodline. She spent her days studying the ancient tomes in the dusty library of the village, unlocking secrets of the universe and casting spells that could bend reality to her will. Her most trusted companion, a sturdy dwarf named Grimbold"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cef2bf2878e8>\u001b[0m in \u001b[0;36m<cell line: 309>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;31m#print('\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-cef2bf2878e8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m   \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfmr_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_tokens4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-cef2bf2878e8>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(xfmr_weights, model_params, tokens)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcur_pos\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcur_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m       \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkvcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxfmr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfmr_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs_cis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcur_pos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkvcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m       \u001b[0mnext_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m       \u001b[0mgen_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d4dfea535cbb>\u001b[0m in \u001b[0;36mxfmr\u001b[0;34m(xfmr_weights, model_params, tokens, cur_pos, freqs_cis, kvcache, attn_mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mnorm_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrms_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfmr_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mh_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkvcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfmr_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs_cis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkvcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfmr_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfmr_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d4dfea535cbb>\u001b[0m in \u001b[0;36mattention\u001b[0;34m(x, layer_weights, model_params, cur_pos, layer_idx, freqs_cis, kvcache, attn_mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mxv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_local_kv_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mxq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_rotary_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs_cis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreqs_cis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkvcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkvcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0mxq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, seqlen, head_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, head_dim, cache_len + seqlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-ea4a6279cef3>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, xk, xv, layer_idx, cur_pos, n_rep)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKVCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/array.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             out.aval, sharding, [out], committed=False, _skip_checks=True)\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax_numpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewriting_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   8951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8952\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8953\u001b[0;31m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0m\u001b[1;32m   8954\u001b[0m                  unique_indices, mode, fill_value)\n\u001b[1;32m   8955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   8981\u001b[0m   \u001b[0;31m# We avoid generating a gather when indexer.gather_indices.size is empty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8982\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8983\u001b[0;31m     y = lax.gather(\n\u001b[0m\u001b[1;32m   8984\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_slice_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8985\u001b[0m       \u001b[0munique_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_indices\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/slicing.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(operand, start_indices, dimension_numbers, slice_sizes, unique_indices, indices_are_sorted, mode, fill_value)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m   return gather_p.bind(\n\u001b[0m\u001b[1;32m    348\u001b[0m       \u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_numbers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension_numbers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0mslice_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    437\u001b[0m     assert (not config.enable_checks.value or\n\u001b[1;32m    438\u001b[0m             all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_top_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpop_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcall_impl_with_key_reuse_checks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_jit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_thread_local_state_disable_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_jit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_thread_local_state_disable_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}