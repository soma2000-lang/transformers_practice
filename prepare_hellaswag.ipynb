{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl_file(path):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Data/HellaSwag_Consolidated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aya_8b_chat_hs_eval_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/LMEvalHarness_Runs/aya-23-8b-hellaswag_with_okapi_with_template/aya-23-8B'\n",
    "aya_8b_no_chat_hs_eval_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/LMEvalHarness_Runs/aya-23-8b-hellaswag_with_okapi_without_template/aya-23-8B'\n",
    "aya_35b_chat_hs_eval_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/LMEvalHarness_Runs/aya-23-35B-hellaswag_with_okapi_with_template/aya-23-35B'\n",
    "aya_35b_no_chat_hs_eval_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/LMEvalHarness_Runs/aya-23-35B-hellaswag_with_okapi_without_template/aya-23-35B'\n",
    "\n",
    "aya_8b_ppl_chat_hs_eval_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/aya_23_8b_chat_ppl_hellaswag_with_okapi_with_template/aya-23-8B'\n",
    "aya_8b_ppl_no_chat_hs_eval_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/aya-23-8B-ppl_hellaswag_with_okapi_without_template/aya-23-8B'\n",
    "aya_35b_ppl_chat_hs_eval_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/aya_23_35B_chat_ppl_hellaswag_with_okapi_with_template/aya-23-35B'\n",
    "aya_35b_ppl_no_chat_hs_eval_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/aya-23-35B-ppl_hellaswag_with_okapi_without_template/aya-23-35B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_aya_8b_chat_hs_eval = os.listdir(aya_8b_chat_hs_eval_path)\n",
    "files_aya_8b_no_chat_hs_eval = os.listdir(aya_8b_no_chat_hs_eval_path)\n",
    "files_aya_35b_chat_hs_eval = os.listdir(aya_35b_chat_hs_eval_path)\n",
    "files_aya_35b_no_chat_hs_eval = os.listdir(aya_35b_no_chat_hs_eval_path)\n",
    "\n",
    "files_aya_8b_ppl_chat_hs_eval = os.listdir(aya_8b_ppl_chat_hs_eval_path)\n",
    "files_aya_8b_ppl_no_chat_hs_eval = os.listdir(aya_8b_ppl_no_chat_hs_eval_path)\n",
    "files_aya_35b_ppl_chat_hs_eval = os.listdir(aya_35b_ppl_chat_hs_eval_path)\n",
    "files_aya_35b_ppl_no_chat_hs_eval = os.listdir(aya_35b_ppl_no_chat_hs_eval_path)\n",
    "\n",
    "# Check sizes \n",
    "assert len(files_aya_8b_chat_hs_eval) == len(files_aya_8b_no_chat_hs_eval) == len(files_aya_35b_chat_hs_eval) == len(files_aya_35b_no_chat_hs_eval) == len(files_aya_8b_ppl_chat_hs_eval) == len(files_aya_8b_ppl_no_chat_hs_eval) == len(files_aya_35b_ppl_chat_hs_eval) == len(files_aya_35b_ppl_no_chat_hs_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort\n",
    "files_aya_8b_chat_hs_eval.sort()\n",
    "files_aya_8b_no_chat_hs_eval.sort()\n",
    "files_aya_35b_chat_hs_eval.sort()\n",
    "files_aya_35b_no_chat_hs_eval.sort()\n",
    "\n",
    "files_aya_8b_ppl_chat_hs_eval.sort()\n",
    "files_aya_8b_ppl_no_chat_hs_eval.sort()\n",
    "files_aya_35b_ppl_chat_hs_eval.sort()\n",
    "files_aya_35b_ppl_no_chat_hs_eval.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove .json files\n",
    "files_aya_8b_chat_hs_eval = [f for f in files_aya_8b_chat_hs_eval if 'jsonl' in f]\n",
    "files_aya_8b_no_chat_hs_eval = [f for f in files_aya_8b_no_chat_hs_eval if 'jsonl' in f]\n",
    "files_aya_35b_chat_hs_eval = [f for f in files_aya_35b_chat_hs_eval if 'jsonl' in f]\n",
    "files_aya_35b_no_chat_hs_eval = [f for f in files_aya_35b_no_chat_hs_eval if 'jsonl' in f]\n",
    "\n",
    "files_aya_8b_ppl_chat_hs_eval = [f for f in files_aya_8b_ppl_chat_hs_eval if 'jsonl' in f]\n",
    "files_aya_8b_ppl_no_chat_hs_eval = [f for f in files_aya_8b_ppl_no_chat_hs_eval if 'jsonl' in f]\n",
    "files_aya_35b_ppl_chat_hs_eval = [f for f in files_aya_35b_ppl_chat_hs_eval if 'jsonl' in f]\n",
    "files_aya_35b_ppl_no_chat_hs_eval = [f for f in files_aya_35b_ppl_no_chat_hs_eval if 'jsonl' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_names = {\n",
    "    'ar': 'Arabic', 'zh': 'Chinese', 'cs': 'Czech', 'nl': 'Dutch', 'en': 'English', 'fr': 'French',\n",
    "    'de': 'German', 'el': 'Greek', 'he': 'Hebrew', 'hi': 'Hindi', 'id': 'Indonesian', 'it': 'Italian',\n",
    "    'ja': 'Japanese', 'ko': 'Korean', 'fa': 'Persian', 'pl': 'Polish', 'pt': 'Portuguese', 'ro': 'Romanian',\n",
    "    'ru': 'Russian', 'es': 'Spanish', 'tr': 'Turkish', 'uk': 'Ukrainian', 'vi': 'Vietnamese',\n",
    "    'te': 'Telugu', 'ta': 'Tamil', 'sv': 'Swedish', 'sr': 'Serbian', 'sk': 'Slovak',\n",
    "    'ne': 'Nepali', 'mr': 'Marathi', 'ml': 'Malayalam', 'kn': 'Kannada', 'hy': 'Armenian',\n",
    "    'hu': 'Hungarian', 'hr': 'Croatian', 'gu': 'Gujarati', 'eu': 'Basque', 'da': 'Danish',\n",
    "    'ca': 'Catalan', 'bn': 'Bengali'\n",
    "}\n",
    "\n",
    "len(language_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_files_aya_8b_chat_hs_eval = {}\n",
    "\n",
    "for file in files_aya_8b_chat_hs_eval:\n",
    "    # remove 'samples_' from the file name\n",
    "    lang = file.split('_2024')[0].split('samples_')[1]\n",
    "    if '_' not in lang:\n",
    "        lang = lang + '_en'\n",
    "\n",
    "    mapping_files_aya_8b_chat_hs_eval[lang] = file\n",
    "\n",
    "mapping_files_aya_8b_no_chat_hs_eval = {}\n",
    "\n",
    "for file in files_aya_8b_no_chat_hs_eval:\n",
    "    # remove 'samples_' from the file name\n",
    "    lang = file.split('_2024')[0].split('samples_')[1]\n",
    "    if '_' not in lang:\n",
    "        lang = lang + '_en'\n",
    "\n",
    "    mapping_files_aya_8b_no_chat_hs_eval[lang] = file\n",
    "\n",
    "mapping_files_aya_35b_chat_hs_eval = {}\n",
    "    # remove 'samples_' from the file name\n",
    "for file in files_aya_35b_chat_hs_eval:\n",
    "    lang = file.split('_2024')[0].split('samples_')[1]\n",
    "    if '_' not in lang:\n",
    "        lang = lang + '_en'\n",
    "\n",
    "    mapping_files_aya_35b_chat_hs_eval[lang] = file\n",
    "\n",
    "mapping_files_aya_35b_no_chat_hs_eval = {}\n",
    "\n",
    "for file in files_aya_35b_no_chat_hs_eval:\n",
    "    # remove 'samples_' from the file name\n",
    "    lang = file.split('_2024')[0].split('samples_')[1]\n",
    "    if '_' not in lang:\n",
    "        lang = lang + '_en'\n",
    "\n",
    "    mapping_files_aya_35b_no_chat_hs_eval[lang] = file\n",
    "\n",
    "mapping_files_aya_8b_ppl_chat_hs_eval = {}\n",
    "\n",
    "for file in files_aya_8b_ppl_chat_hs_eval:\n",
    "    # remove 'samples_' from the file name\n",
    "    lang = file.split('_2024')[0].split('samples_')[1]\n",
    "    # remove '_no_chat_ppl' from the language name\n",
    "    lang = lang.replace('_no_chat_ppl', '')\n",
    "    # remove '__ppl'\n",
    "    lang = lang.replace('_ppl', '')\n",
    "    # remove '_chat'\n",
    "    lang = lang.replace('_chat', '')\n",
    "    if '_' not in lang:\n",
    "        lang = lang + '_en'\n",
    "\n",
    "    mapping_files_aya_8b_ppl_chat_hs_eval[lang] = file\n",
    "\n",
    "mapping_files_aya_8b_ppl_no_chat_hs_eval = {}\n",
    "\n",
    "for file in files_aya_8b_ppl_no_chat_hs_eval:\n",
    "    # remove 'samples_' from the file name\n",
    "    lang = file.split('_2024')[0].split('samples_')[1]\n",
    "    # remove '_no_chat_ppl' from the language name\n",
    "    lang = lang.replace('_no_chat_ppl', '')\n",
    "    # remove '__ppl'\n",
    "    lang = lang.replace('_ppl', '')\n",
    "    # remove '_chat'\n",
    "    lang = lang.replace('_chat', '')\n",
    "    if '_' not in lang:\n",
    "        lang = lang + '_en'\n",
    "\n",
    "    mapping_files_aya_8b_ppl_no_chat_hs_eval[lang] = file\n",
    "\n",
    "mapping_files_aya_35b_ppl_chat_hs_eval = {}\n",
    "\n",
    "for file in files_aya_35b_ppl_chat_hs_eval:\n",
    "    # remove 'samples_' from the file name\n",
    "    lang = file.split('_2024')[0].split('samples_')[1]\n",
    "    # remove '_no_chat_ppl' from the language name\n",
    "    lang = lang.replace('_no_chat_ppl', '')\n",
    "    # remove '__ppl'\n",
    "    lang = lang.replace('_ppl', '')\n",
    "    # remove '_chat'\n",
    "    lang = lang.replace('_chat', '')\n",
    "    if '_' not in lang:\n",
    "        lang = lang + '_en'\n",
    "\n",
    "    mapping_files_aya_35b_ppl_chat_hs_eval[lang] = file\n",
    "\n",
    "mapping_files_aya_35b_ppl_no_chat_hs_eval = {}\n",
    "\n",
    "for file in files_aya_35b_ppl_no_chat_hs_eval:\n",
    "    # remove 'samples_' from the file name\n",
    "    lang = file.split('_2024')[0].split('samples_')[1]\n",
    "    # remove '_no_chat_ppl' from the language name\n",
    "    lang = lang.replace('_no_chat_ppl', '')\n",
    "    # remove '__ppl'\n",
    "    lang = lang.replace('_ppl', '')\n",
    "    # remove '_chat'\n",
    "    lang = lang.replace('_chat', '')\n",
    "    if '_' not in lang:\n",
    "        lang = lang + '_en'\n",
    "\n",
    "    mapping_files_aya_35b_ppl_no_chat_hs_eval[lang] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check keys should be the same\n",
    "\n",
    "assert len(list(mapping_files_aya_8b_chat_hs_eval.keys())) == len(list(mapping_files_aya_8b_no_chat_hs_eval.keys())) == len(list(mapping_files_aya_35b_chat_hs_eval.keys())) == len(list(mapping_files_aya_35b_no_chat_hs_eval.keys())) == len(list(mapping_files_aya_8b_ppl_chat_hs_eval.keys())) == len(list(mapping_files_aya_8b_ppl_no_chat_hs_eval.keys())) == len(list(mapping_files_aya_35b_ppl_chat_hs_eval.keys())) == len(list(mapping_files_aya_35b_ppl_no_chat_hs_eval.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_eval_file(path):\n",
    "    ls_acc = []\n",
    "    ls_acc_norm = []\n",
    "    rows = read_jsonl_file(path)\n",
    "    for row in rows:\n",
    "        acc = row['acc']\n",
    "        acc_norm = row['acc_norm']\n",
    "        ls_acc.append(acc)\n",
    "        ls_acc_norm.append(acc_norm)\n",
    "    return ls_acc, ls_acc_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ppl_file(path):\n",
    "    ls_log_likelihood = []\n",
    "    ls_num_words = []\n",
    "    ls_num_bytes = []\n",
    "    ls_num_bits_per_byte = []\n",
    "    rows = read_jsonl_file(path)\n",
    "    for row in rows:\n",
    "        word_perplexity = row['word_perplexity']\n",
    "        byte_perplexity = row['byte_perplexity']\n",
    "        bits_per_byte = row['bits_per_byte']\n",
    "        log_likelihood = word_perplexity[0]\n",
    "        num_words = word_perplexity[1]\n",
    "        num_bytes = byte_perplexity[1]\n",
    "        num_bits_per_byte = bits_per_byte[1]\n",
    "\n",
    "        assert word_perplexity[0] == byte_perplexity[0] == bits_per_byte[0], 'Log likelihoods do not match'\n",
    "        \n",
    "        ls_log_likelihood.append(log_likelihood)\n",
    "        ls_num_words.append(num_words)\n",
    "        ls_num_bytes.append(num_bytes)\n",
    "        ls_num_bits_per_byte.append(num_bits_per_byte)\n",
    "    return ls_log_likelihood, ls_num_words, ls_num_bytes, ls_num_bits_per_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_eval_file(os.path.join(aya_8b_chat_hs_eval_path, files_aya_8b_chat_hs_eval[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_ppl_file(os.path.join(aya_8b_ppl_chat_hs_eval_path, files_aya_8b_ppl_chat_hs_eval[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aya 8B Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellaswag_zh\n",
      "hellaswag_cs\n",
      "hellaswag_el\n",
      "hellaswag_he\n",
      "hellaswag_ja\n",
      "hellaswag_ko\n",
      "hellaswag_fa\n",
      "hellaswag_pl\n",
      "hellaswag_tr\n"
     ]
    }
   ],
   "source": [
    "for language in language_names.keys():\n",
    "    key = 'hellaswag_' + language\n",
    "    key_in_eval = key in list(mapping_files_aya_8b_chat_hs_eval.keys())\n",
    "    key_in_ppl = key in list(mapping_files_aya_8b_ppl_chat_hs_eval.keys())\n",
    "\n",
    "    if key_in_eval:\n",
    "        if not key_in_ppl:\n",
    "            print(key)\n",
    "            raise ValueError('Key not found in PPL but found in eval')\n",
    "    \n",
    "    if key_in_ppl:\n",
    "        if not key_in_eval:\n",
    "            print(key)\n",
    "            raise ValueError('Key not found in eval but found in PPL')\n",
    "\n",
    "    if key_in_eval == False and key_in_ppl == False:\n",
    "        print(key)\n",
    "        continue\n",
    "\n",
    "    eval_file_path = mapping_files_aya_8b_chat_hs_eval[key]\n",
    "    ppl_file_path = mapping_files_aya_8b_ppl_chat_hs_eval[key]\n",
    "\n",
    "    acc, acc_norm = parse_eval_file(os.path.join(aya_8b_chat_hs_eval_path, eval_file_path))\n",
    "    log_likelihood, num_words, num_bytes, num_bits_per_byte = parse_ppl_file(os.path.join(aya_8b_ppl_chat_hs_eval_path, ppl_file_path))\n",
    "\n",
    "    ls_word_perplexity = []\n",
    "\n",
    "    ls_byte_perplexity = []\n",
    "\n",
    "    for llk, nw, nb in zip(log_likelihood, num_words, num_bytes):\n",
    "        word_ppl = exp(-1 * llk / nw)\n",
    "        byte_ppl = exp(-1 * llk / nb)\n",
    "        ls_word_perplexity.append(word_ppl)\n",
    "        ls_byte_perplexity.append(byte_ppl)\n",
    "\n",
    "\n",
    "    assert len(acc) == len(acc_norm) == len(log_likelihood) == len(num_words) == len(num_bytes) == len(num_bits_per_byte) == len(ls_word_perplexity) == len(ls_byte_perplexity)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'acc': acc,\n",
    "        'acc_norm': acc_norm,\n",
    "        'log_likelihood': log_likelihood,\n",
    "        'num_words': num_words,\n",
    "        'num_bytes': num_bytes,\n",
    "        'num_bits_per_byte': num_bits_per_byte,\n",
    "        'word_perplexity': ls_word_perplexity,\n",
    "        'byte_perplexity': ls_byte_perplexity\n",
    "    })\n",
    "\n",
    "    language_name = language_names[language]\n",
    "\n",
    "    df.to_csv(os.path.join(save_path, language_name + '_8b_chat.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aya 8B No Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellaswag_zh\n",
      "hellaswag_cs\n",
      "hellaswag_el\n",
      "hellaswag_he\n",
      "hellaswag_ja\n",
      "hellaswag_ko\n",
      "hellaswag_fa\n",
      "hellaswag_pl\n",
      "hellaswag_tr\n"
     ]
    }
   ],
   "source": [
    "for language in language_names.keys():\n",
    "    key = 'hellaswag_' + language\n",
    "    key_in_eval = key in list(mapping_files_aya_8b_no_chat_hs_eval.keys())\n",
    "    key_in_ppl = key in list(mapping_files_aya_8b_ppl_no_chat_hs_eval.keys())\n",
    "\n",
    "    if key_in_eval:\n",
    "        if not key_in_ppl:\n",
    "            print(key)\n",
    "            raise ValueError('Key not found in PPL but found in eval')\n",
    "    \n",
    "    if key_in_ppl:\n",
    "        if not key_in_eval:\n",
    "            print(key)\n",
    "            raise ValueError('Key not found in eval but found in PPL')\n",
    "\n",
    "    if key_in_eval == False and key_in_ppl == False:\n",
    "        print(key)\n",
    "        continue\n",
    "\n",
    "    eval_file_path = mapping_files_aya_8b_no_chat_hs_eval[key]\n",
    "    ppl_file_path = mapping_files_aya_8b_ppl_no_chat_hs_eval[key]\n",
    "\n",
    "    acc, acc_norm = parse_eval_file(os.path.join(aya_8b_no_chat_hs_eval_path, eval_file_path))\n",
    "    log_likelihood, num_words, num_bytes, num_bits_per_byte = parse_ppl_file(os.path.join(aya_8b_ppl_no_chat_hs_eval_path, ppl_file_path))\n",
    "\n",
    "    ls_word_perplexity = []\n",
    "\n",
    "    ls_byte_perplexity = []\n",
    "\n",
    "    for llk, nw, nb in zip(log_likelihood, num_words, num_bytes):\n",
    "        word_ppl = exp(-1 * llk / nw)\n",
    "        byte_ppl = exp(-1 * llk / nb)\n",
    "        ls_word_perplexity.append(word_ppl)\n",
    "        ls_byte_perplexity.append(byte_ppl)\n",
    "\n",
    "\n",
    "    assert len(acc) == len(acc_norm) == len(log_likelihood) == len(num_words) == len(num_bytes) == len(num_bits_per_byte) == len(ls_word_perplexity) == len(ls_byte_perplexity)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'acc': acc,\n",
    "        'acc_norm': acc_norm,\n",
    "        'log_likelihood': log_likelihood,\n",
    "        'num_words': num_words,\n",
    "        'num_bytes': num_bytes,\n",
    "        'num_bits_per_byte': num_bits_per_byte,\n",
    "        'word_perplexity': ls_word_perplexity,\n",
    "        'byte_perplexity': ls_byte_perplexity\n",
    "    })\n",
    "\n",
    "    language_name = language_names[language]\n",
    "\n",
    "    df.to_csv(os.path.join(save_path, language_name + '_8b_no_chat.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aya 35B Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samples_hellaswag_hr_2024-08-06T07-40-36.390030.jsonl'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_files_aya_35b_chat_hs_eval['hellaswag_hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samples_hellaswag_hr_chat_ppl_2024-08-08T20-54-22.090752.jsonl'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_files_aya_35b_ppl_chat_hs_eval['hellaswag_hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = parse_eval_file(os.path.join(aya_35b_chat_hs_eval_path, mapping_files_aya_35b_chat_hs_eval['hellaswag_hr']))\n",
    "f2 = parse_ppl_file(os.path.join(aya_35b_ppl_chat_hs_eval_path, mapping_files_aya_35b_ppl_chat_hs_eval['hellaswag_hr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellaswag_zh\n",
      "hellaswag_cs\n",
      "hellaswag_el\n",
      "hellaswag_he\n",
      "hellaswag_ja\n",
      "hellaswag_ko\n",
      "hellaswag_fa\n",
      "hellaswag_pl\n",
      "hellaswag_tr\n",
      "7583 7583 9471 9471 9471 9471 9471 9471 for hr\n",
      "hr\n"
     ]
    }
   ],
   "source": [
    "for language in language_names.keys():\n",
    "    key = 'hellaswag_' + language\n",
    "    key_in_eval = key in list(mapping_files_aya_35b_chat_hs_eval.keys())\n",
    "    key_in_ppl = key in list(mapping_files_aya_35b_ppl_chat_hs_eval.keys())\n",
    "\n",
    "    if key_in_eval:\n",
    "        if not key_in_ppl:\n",
    "            print(key)\n",
    "            raise ValueError('Key not found in PPL but found in eval')\n",
    "    \n",
    "    if key_in_ppl:\n",
    "        if not key_in_eval:\n",
    "            print(key)\n",
    "            raise ValueError('Key not found in eval but found in PPL')\n",
    "\n",
    "    if key_in_eval == False and key_in_ppl == False:\n",
    "        print(key)\n",
    "        continue\n",
    "\n",
    "    eval_file_path = mapping_files_aya_35b_chat_hs_eval[key]\n",
    "    ppl_file_path = mapping_files_aya_35b_ppl_chat_hs_eval[key]\n",
    "\n",
    "    acc, acc_norm = parse_eval_file(os.path.join(aya_35b_chat_hs_eval_path, eval_file_path))\n",
    "    log_likelihood, num_words, num_bytes, num_bits_per_byte = parse_ppl_file(os.path.join(aya_35b_ppl_chat_hs_eval_path, ppl_file_path))\n",
    "\n",
    "    ls_word_perplexity = []\n",
    "\n",
    "    ls_byte_perplexity = []\n",
    "\n",
    "    for llk, nw, nb in zip(log_likelihood, num_words, num_bytes):\n",
    "        word_ppl = exp(-1 * llk / nw)\n",
    "        byte_ppl = exp(-1 * llk / nb)\n",
    "        ls_word_perplexity.append(word_ppl)\n",
    "        ls_byte_perplexity.append(byte_ppl)\n",
    "\n",
    "    try:\n",
    "        assert len(acc) == len(acc_norm) == len(log_likelihood) == len(num_words) == len(num_bytes) == len(num_bits_per_byte) == len(ls_word_perplexity) == len(ls_byte_perplexity), f'{len(acc)} {len(acc_norm)} {len(log_likelihood)} {len(num_words)} {len(num_bytes)} {len(num_bits_per_byte)} {len(ls_word_perplexity)} {len(ls_byte_perplexity)} for {language}'\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'acc': acc,\n",
    "            'acc_norm': acc_norm,\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'num_words': num_words,\n",
    "            'num_bytes': num_bytes,\n",
    "            'num_bits_per_byte': num_bits_per_byte,\n",
    "            'word_perplexity': ls_word_perplexity,\n",
    "            'byte_perplexity': ls_byte_perplexity\n",
    "        })\n",
    "\n",
    "        language_name = language_names[language]\n",
    "\n",
    "        df.to_csv(os.path.join(save_path, language_name + '_35b_chat.csv'), index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(language)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aya 35B No Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellaswag_zh\n",
      "hellaswag_cs\n",
      "hellaswag_el\n",
      "hellaswag_he\n",
      "hellaswag_ja\n",
      "hellaswag_ko\n",
      "hellaswag_fa\n",
      "hellaswag_pl\n",
      "hellaswag_tr\n"
     ]
    }
   ],
   "source": [
    "for language in language_names.keys():\n",
    "    key = 'hellaswag_' + language\n",
    "    key_in_eval = key in list(mapping_files_aya_35b_no_chat_hs_eval.keys())\n",
    "    key_in_ppl = key in list(mapping_files_aya_35b_ppl_no_chat_hs_eval.keys())\n",
    "\n",
    "    if key_in_eval:\n",
    "        if not key_in_ppl:\n",
    "            print(key)\n",
    "            raise ValueError('Key not found in PPL but found in eval')\n",
    "    \n",
    "    if key_in_ppl:\n",
    "        if not key_in_eval:\n",
    "            print(key)\n",
    "            raise ValueError('Key not found in eval but found in PPL')\n",
    "\n",
    "    if key_in_eval == False and key_in_ppl == False:\n",
    "        print(key)\n",
    "        continue\n",
    "\n",
    "    eval_file_path = mapping_files_aya_35b_no_chat_hs_eval[key]\n",
    "    ppl_file_path = mapping_files_aya_35b_ppl_no_chat_hs_eval[key]\n",
    "\n",
    "    acc, acc_norm = parse_eval_file(os.path.join(aya_35b_no_chat_hs_eval_path, eval_file_path))\n",
    "    log_likelihood, num_words, num_bytes, num_bits_per_byte = parse_ppl_file(os.path.join(aya_35b_ppl_no_chat_hs_eval_path, ppl_file_path))\n",
    "\n",
    "    ls_word_perplexity = []\n",
    "\n",
    "    ls_byte_perplexity = []\n",
    "\n",
    "    for llk, nw, nb in zip(log_likelihood, num_words, num_bytes):\n",
    "        word_ppl = exp(-1 * llk / nw)\n",
    "        byte_ppl = exp(-1 * llk / nb)\n",
    "        ls_word_perplexity.append(word_ppl)\n",
    "        ls_byte_perplexity.append(byte_ppl)\n",
    "\n",
    "\n",
    "    assert len(acc) == len(acc_norm) == len(log_likelihood) == len(num_words) == len(num_bytes) == len(num_bits_per_byte) == len(ls_word_perplexity) == len(ls_byte_perplexity)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'acc': acc,\n",
    "        'acc_norm': acc_norm,\n",
    "        'log_likelihood': log_likelihood,\n",
    "        'num_words': num_words,\n",
    "        'num_bytes': num_bytes,\n",
    "        'num_bits_per_byte': num_bits_per_byte,\n",
    "        'word_perplexity': ls_word_perplexity,\n",
    "        'byte_perplexity': ls_byte_perplexity\n",
    "    })\n",
    "\n",
    "    language_name = language_names[language]\n",
    "\n",
    "    df.to_csv(os.path.join(save_path, language_name + '_35b_no_chat.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
