{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b075d78-e3c2-45e0-b109-9eaa27879b2a",
   "metadata": {},
   "source": [
    "# Imports  - many typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4bbc2b5-977d-46f0-bd8c-a2828ab8c011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pydantic openai_api_key **********\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"llmapslab\")\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from openai_client import client, call_openai_api\n",
    "\n",
    "import json\n",
    "import re\n",
    "import load_configs\n",
    "import importlib\n",
    "importlib.reload(load_configs)\n",
    "from load_configs import (\n",
    "    openai_api_key,\n",
    "    llama_api_key, ai21_api_key, \n",
    "    gemini_api_key\n",
    ")\n",
    "from openai_client import call_openai_api\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "print('pydantic openai_api_key', openai_api_key)  #### openai_api_key.get_secret_value()  will print actual key\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key.get_secret_value()\n",
    "\n",
    "from typing import (\n",
    "    List, Sequence, Tuple, Callable, Optional, Union, Literal,\n",
    "    TYPE_CHECKING, Any\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf339e-7eb5-46f6-a6e5-322ec6d3de29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7196e07b-ae11-4022-b010-7f33a238433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': 'completion', 'parsed': 'noitelpmoc'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    origin=RunnablePassthrough(),\n",
    "    modified=lambda x: x+1\n",
    ")\n",
    "\n",
    "runnable.invoke(1) # {'origin': 1, 'modified': 2}\n",
    "\n",
    "\n",
    "def fake_llm(prompt: str) -> str: # Fake LLM for the example\n",
    "    return \"completion\"\n",
    "\n",
    "chain = RunnableLambda(fake_llm) | {\n",
    "    'original': RunnablePassthrough(), # Original LLM output\n",
    "    'parsed': lambda text: text[::-1] # Parsing logic\n",
    "}\n",
    "\n",
    "chain.invoke('hello') # {'original': 'completion', 'parsed': 'noitelpmoc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef75a9db-4882-4232-bdfe-46bb0f328db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm1': 'completion', 'llm2': 'completion', 'total_chars': 20}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fake_llm(prompt: str) -> str: # Fake LLM for the example\n",
    "    return \"completion\"\n",
    "\n",
    "runnable = {\n",
    "    'llm1':  fake_llm,\n",
    "    'llm2':  fake_llm,\n",
    "} | RunnablePassthrough.assign(\n",
    "    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2'])\n",
    ")\n",
    "\n",
    "runnable.invoke('hello')\n",
    "# {'llm1': 'completion', 'llm2': 'completion', 'total_chars': 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0db0e-790b-4341-af35-a54d2cdba21a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Original csv_agent testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0239d747-198b-40d1-8d17-26dbf329caae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/country_eng.csv', '../data/custom_2020.csv', '../data/Mobile-Price-Prediction-cleaned_data.csv']\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(\"../data\")\n",
    "os.path.exists(data_path)\n",
    "csv_files = glob(f\"{data_path}/*.csv\")\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afb098a-6148-4a93-9778-325d14f4c4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      232\n",
       "Country         232\n",
       "Country_name    232\n",
       "Area            232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfile = csv_files[0]\n",
    "df_small = pd.read_csv(sfile)\n",
    "df_small.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2be6064-683a-411f-8a16-5149a692e01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp_imp    3299804\n",
       "Year       3299804\n",
       "month      3299804\n",
       "ym         3299804\n",
       "Country    3299804\n",
       "Custom     3299804\n",
       "hs2        3299804\n",
       "hs4        3299804\n",
       "hs6        3299804\n",
       "hs9        3299804\n",
       "Q1         3299804\n",
       "Q2         3299804\n",
       "Value      3299804\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfile = csv_files[1]\n",
    "df_large = pd.read_csv(lfile)\n",
    "df_large.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f4b538-b417-4f2a-ae1b-cbc855e90977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=openai_api_key,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    # model=\"gpt-4o-mini-2024-07-18\",\n",
    "    # model=\"gpt-4o\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c550d2a-8a85-419e-8c46-b50e0c6b0310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f01dab6ffd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f01dab7e9a0>, model_name='gpt-4o-mini-2024-07-18', openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm  ### Notice that the api key is not printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d06a85-293e-4a1e-bc85-dae000b0b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00e00be6-756a-4c1c-8205-731e6cc52650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/country_eng.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e4d01a-a28f-4bea-a9ba-962846850d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'len(df)'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m232\u001b[0m\u001b[32;1m\u001b[1;3mThere are 232 rows in the dataframe `df`.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 232 rows in the dataframe `df`.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_csv_agent(\n",
    "    llm,\n",
    "    sfile,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    allow_dangerous_code=True,\n",
    "    verbose=True\n",
    ")\n",
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0f5ac6b-25f4-4bce-8179-43e64e1354e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the number of rows in the dataframe `df`, I can use the `shape` attribute of the dataframe, which returns a tuple with the number of rows and columns. I'll access the first element of this tuple to get the row count.\n",
      "Action: python_repl_ast\n",
      "Action Input: df.shape[0]\u001b[0m\u001b[36;1m\u001b[1;3m232\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 232\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'232'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_csv_agent(\n",
    "    llm,\n",
    "    sfile,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    allow_dangerous_code=True,\n",
    "    verbose=True\n",
    ")\n",
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a9b65f5-56e9-4f55-8d9b-e5a5a5813eec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'len(df)'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m232\u001b[0m\u001b[32;1m\u001b[1;3mThere are 232 rows in the dataframe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There are 232 rows in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "agent = create_csv_agent(\n",
    "    llm,\n",
    "    sfile,\n",
    "    agent_type=\"tool-calling\", #AgentType.OPENAI_FUNCTIONS,\n",
    "    allow_dangerous_code=True,\n",
    "    verbose=True,\n",
    "    # return_intermediate_steps=True,\n",
    "    # return_direct=True,\n",
    "    # response_format='content_and_artifact'\n",
    ")\n",
    "res = agent.run(input=\"how many rows are there?\", \n",
    "                # return_direct=True,\n",
    "    # response_format='content_and_artifact'\n",
    "                # return_intermediate_steps=True,\n",
    "               )\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00eb63-aa6c-4498-ad2a-27338ba222a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c497872e-d96e-4b3a-ae01-028c72a436c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Dict[str, typing.Any]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent.get_allowed_tools()\n",
    "agent.OutputType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "587de43a-3342-48c6-abf3-610c677089cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c0a9729-9c9a-45da-b92c-d15d5c7ce233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.output_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "241f6df9-ed79-40e8-bc21-f86d8bd715ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.return_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5883e30-42e8-4014-9154-f84ef96ace08",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.tools[0].return_direct = True\n",
    "agent.tools[0].response_format='content'#'content_and_artifact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef610cfe-8540-438f-9bc4-0a3142d18c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'len(df)'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m232\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "res = agent.run(input=\"how many rows are there?\",)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "347183fb-3050-4070-9c3d-3fb421c60dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df['Country_name'].tolist()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Korea', 'North_Korea', 'China', 'Taiwan', 'Mongolia', 'Hong_Kong', 'Viet_Nam', 'Thailand', 'Singapore', 'Malaysia', 'Brunei', 'Philippines', 'Indonesia', 'Cambodia', 'Lao', 'Myanmar', 'India', 'Pakistan', 'Sri_Lanka', 'Maldives', 'Bangladesh', 'Timor-Leste', 'Macao', 'Afghanistan', 'Nepal', 'Bhutan', 'Iran', 'Iraq', 'Bahrain', 'Saudi_Arabia', 'Kuwait', 'Qatar', 'Oman', 'Israel', 'Jordan', 'Syria', 'Lebanon', 'United_Arab_Emirates', 'Yemen', 'Azerbaijan', 'Armenia', 'Uzbekistan', 'Kazakhstan', 'Kyrgyz', 'Tajikistan', 'Turkmenistan', 'Georgia', 'West_Bank_and_Gaza_Strip', 'Iceland', 'Norway', 'Sweden', 'Denmark', 'United_Kingdom', 'Ireland', 'Netherlands', 'Belgium', 'Luxembourg', 'France', 'Monaco', 'Andorra', 'Germany', 'Switzerland', 'Azores_(Portugal)', 'Portugal', 'Spain', 'Gibraltar_(UK)', 'Italy', 'Malta', 'Finland', 'Poland', 'Russia', 'Austria', 'Hungary', 'Serbia', 'Albania', 'Greece', 'Romania', 'Bulgaria', 'Cyprus', 'Turkey', 'Estonia', 'Latvia', 'Lithuania', 'Ukraine', 'Belarus', 'Moldova', 'Croatia', 'Slovenia', 'Bosnia_and_Herzegovina', 'Former_Yugoslav_Republic_of_Macedonia', 'Czech_Republic', 'Slovak', 'Montenegro', 'Kosovo', 'Greenland_(Denmark)', 'Canada', 'St.Pierre_and_Miquelon_(France)', 'United_States_of_America', 'Mexico', 'Guatemala', 'Honduras', 'Belize', 'El_Salvador', 'Nicaragua', 'Costa_Rica', 'Panama', 'Bermuda_(UK)', 'Bahamas', 'Jamaica', 'Turks_and_Caicos_Islands_(UK)', 'Barbados', 'Trinidad_and_Tobago', 'Cuba', 'Haiti', 'Dominican_Republic', 'Puerto_Rico_(USA)', 'US_Virgin_Islands', 'Netherlands_Antilles', 'French_West_Indies', 'Cayman_islands_(UK)', 'Grenada', 'St.Lucia', 'Antigua_and_Barbuda', 'British_Virgin_Islands', 'Dominica', 'Monstserrat_(UK)', 'St.Christopher_and_Nevis', 'St.Vincent', 'British_Anguilla', 'Colombia', 'Venezuela', 'Guyana', 'Suriname', 'French_Guiana', 'Ecuador', 'Peru', 'Bolivia', 'Chile', 'Brazil', 'Paraguay', 'Uruguay', 'Argentina', 'Falkland_Islands_and_Dependencies_(UK)', 'British_Antarctic_Territory', 'Morocco', 'Ceuta_and_Melilla_(Spain)', 'Algeria', 'Tunisia', 'Libya', 'Egypt', 'Sudan', 'West_Sahara', 'Mauritania', 'Senegal', 'Gambia', 'Guinea-Bissau', 'Guinea', 'Sierra_Leone', 'Liberia', \"Côte_d'Ivoire\", 'Ghana', 'Togo', 'Benin', 'Mali', 'Burkina_Faso', 'Cape_Verde', 'Canary_Islands_(Spain)', 'Nigeria', 'Niger', 'Rwanda', 'Cameroon', 'Chad', 'Central_Africa', 'Equatorial_Guinea', 'Gabon', 'Congo', 'Congo', 'Burundi', 'Angola', 'Sao_Tome_and_Principe', 'St._Helena_Island_and_Dependencies_(UK)', 'Ethiopia', 'Djibouti', 'Somalia', 'Kenya', 'Uganda', 'Tanzania', 'Seychelles', 'Mozambique', 'Madagascar', 'Mauritius', 'Reunion_(France)', 'Zimbabwe', 'Namibia', 'South_Africa', 'Lesotho', 'Malawi', 'Zambia', 'Botswana', 'Swaziland', 'British_indian_Ocean_Territories', 'Comoros', 'Eritrea', 'South_Sudan', 'Australia', 'Papua_New_Guinea', 'Other_Australian_Territories', 'New_Zealand', 'Cook', 'Tokelau_Islands_(NZ)', 'Niue', 'Samoa', 'Vanuatu', 'Fiji', 'Solomon_Islands', 'Tonga', 'Kiribati', 'Pitcairn_(UK)', 'Nauru', 'New_Caledonia_(France)', 'French_Polynesia', 'Guam_(USA)', 'American_Samoa', 'American_Oceania', 'Tuvalu', 'Marshall', 'Micronesia', 'Northern_Mariana_Islands_(USA)', 'Palau', 'For_Order', 'Unknown', 'Bonded_Manufacturing_Warehouse']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "['Korea', 'North_Korea', 'China', 'Taiwan', 'Mongolia', 'Hong_Kong', 'Viet_Nam', 'Thailand', 'Singapore', 'Malaysia', 'Brunei', 'Philippines', 'Indonesia', 'Cambodia', 'Lao', 'Myanmar', 'India', 'Pakistan', 'Sri_Lanka', 'Maldives', 'Bangladesh', 'Timor-Leste', 'Macao', 'Afghanistan', 'Nepal', 'Bhutan', 'Iran', 'Iraq', 'Bahrain', 'Saudi_Arabia', 'Kuwait', 'Qatar', 'Oman', 'Israel', 'Jordan', 'Syria', 'Lebanon', 'United_Arab_Emirates', 'Yemen', 'Azerbaijan', 'Armenia', 'Uzbekistan', 'Kazakhstan', 'Kyrgyz', 'Tajikistan', 'Turkmenistan', 'Georgia', 'West_Bank_and_Gaza_Strip', 'Iceland', 'Norway', 'Sweden', 'Denmark', 'United_Kingdom', 'Ireland', 'Netherlands', 'Belgium', 'Luxembourg', 'France', 'Monaco', 'Andorra', 'Germany', 'Switzerland', 'Azores_(Portugal)', 'Portugal', 'Spain', 'Gibraltar_(UK)', 'Italy', 'Malta', 'Finland', 'Poland', 'Russia', 'Austria', 'Hungary', 'Serbia', 'Albania', 'Greece', 'Romania', 'Bulgaria', 'Cyprus', 'Turkey', 'Estonia', 'Latvia', 'Lithuania', 'Ukraine', 'Belarus', 'Moldova', 'Croatia', 'Slovenia', 'Bosnia_and_Herzegovina', 'Former_Yugoslav_Republic_of_Macedonia', 'Czech_Republic', 'Slovak', 'Montenegro', 'Kosovo', 'Greenland_(Denmark)', 'Canada', 'St.Pierre_and_Miquelon_(France)', 'United_States_of_America', 'Mexico', 'Guatemala', 'Honduras', 'Belize', 'El_Salvador', 'Nicaragua', 'Costa_Rica', 'Panama', 'Bermuda_(UK)', 'Bahamas', 'Jamaica', 'Turks_and_Caicos_Islands_(UK)', 'Barbados', 'Trinidad_and_Tobago', 'Cuba', 'Haiti', 'Dominican_Republic', 'Puerto_Rico_(USA)', 'US_Virgin_Islands', 'Netherlands_Antilles', 'French_West_Indies', 'Cayman_islands_(UK)', 'Grenada', 'St.Lucia', 'Antigua_and_Barbuda', 'British_Virgin_Islands', 'Dominica', 'Monstserrat_(UK)', 'St.Christopher_and_Nevis', 'St.Vincent', 'British_Anguilla', 'Colombia', 'Venezuela', 'Guyana', 'Suriname', 'French_Guiana', 'Ecuador', 'Peru', 'Bolivia', 'Chile', 'Brazil', 'Paraguay', 'Uruguay', 'Argentina', 'Falkland_Islands_and_Dependencies_(UK)', 'British_Antarctic_Territory', 'Morocco', 'Ceuta_and_Melilla_(Spain)', 'Algeria', 'Tunisia', 'Libya', 'Egypt', 'Sudan', 'West_Sahara', 'Mauritania', 'Senegal', 'Gambia', 'Guinea-Bissau', 'Guinea', 'Sierra_Leone', 'Liberia', \"Côte_d'Ivoire\", 'Ghana', 'Togo', 'Benin', 'Mali', 'Burkina_Faso', 'Cape_Verde', 'Canary_Islands_(Spain)', 'Nigeria', 'Niger', 'Rwanda', 'Cameroon', 'Chad', 'Central_Africa', 'Equatorial_Guinea', 'Gabon', 'Congo', 'Congo', 'Burundi', 'Angola', 'Sao_Tome_and_Principe', 'St._Helena_Island_and_Dependencies_(UK)', 'Ethiopia', 'Djibouti', 'Somalia', 'Kenya', 'Uganda', 'Tanzania', 'Seychelles', 'Mozambique', 'Madagascar', 'Mauritius', 'Reunion_(France)', 'Zimbabwe', 'Namibia', 'South_Africa', 'Lesotho', 'Malawi', 'Zambia', 'Botswana', 'Swaziland', 'British_indian_Ocean_Territories', 'Comoros', 'Eritrea', 'South_Sudan', 'Australia', 'Papua_New_Guinea', 'Other_Australian_Territories', 'New_Zealand', 'Cook', 'Tokelau_Islands_(NZ)', 'Niue', 'Samoa', 'Vanuatu', 'Fiji', 'Solomon_Islands', 'Tonga', 'Kiribati', 'Pitcairn_(UK)', 'Nauru', 'New_Caledonia_(France)', 'French_Polynesia', 'Guam_(USA)', 'American_Samoa', 'American_Oceania', 'Tuvalu', 'Marshall', 'Micronesia', 'Northern_Mariana_Islands_(USA)', 'Palau', 'For_Order', 'Unknown', 'Bonded_Manufacturing_Warehouse']\n"
     ]
    }
   ],
   "source": [
    "res = agent.run(input=\"list all the countries\",)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dbe6d57-80d5-4f32-b984-269fb4eb7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[['Country_name', 'Area']].head(10)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m  Country_name  Area\n",
      "0        Korea  Asia\n",
      "1  North_Korea  Asia\n",
      "2        China  Asia\n",
      "3       Taiwan  Asia\n",
      "4     Mongolia  Asia\n",
      "5    Hong_Kong  Asia\n",
      "6     Viet_Nam  Asia\n",
      "7     Thailand  Asia\n",
      "8    Singapore  Asia\n",
      "9     Malaysia  Asia\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "  Country_name  Area\n",
      "0        Korea  Asia\n",
      "1  North_Korea  Asia\n",
      "2        China  Asia\n",
      "3       Taiwan  Asia\n",
      "4     Mongolia  Asia\n",
      "5    Hong_Kong  Asia\n",
      "6     Viet_Nam  Asia\n",
      "7     Thailand  Asia\n",
      "8    Singapore  Asia\n",
      "9     Malaysia  Asia\n"
     ]
    }
   ],
   "source": [
    "res = agent.run(input=\" give me the 10 country name and the area both\",)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b43cf1c8-b63c-44e5-8e4e-a691e84ebd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df['Country_name'].head(10).tolist()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Korea', 'North_Korea', 'China', 'Taiwan', 'Mongolia', 'Hong_Kong', 'Viet_Nam', 'Thailand', 'Singapore', 'Malaysia']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df['Area'].head(10).tolist()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Asia', 'Asia', 'Asia', 'Asia', 'Asia', 'Asia', 'Asia', 'Asia', 'Asia', 'Asia']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHere are the first 10 country names:\n",
      "\n",
      "1. Korea\n",
      "2. North Korea\n",
      "3. China\n",
      "4. Taiwan\n",
      "5. Mongolia\n",
      "6. Hong Kong\n",
      "7. Viet Nam\n",
      "8. Thailand\n",
      "9. Singapore\n",
      "10. Malaysia\n",
      "\n",
      "And here are the corresponding areas for each of these countries:\n",
      "\n",
      "1. Asia\n",
      "2. Asia\n",
      "3. Asia\n",
      "4. Asia\n",
      "5. Asia\n",
      "6. Asia\n",
      "7. Asia\n",
      "8. Asia\n",
      "9. Asia\n",
      "10. Asia\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Here are the first 10 country names:\n",
      "\n",
      "1. Korea\n",
      "2. North Korea\n",
      "3. China\n",
      "4. Taiwan\n",
      "5. Mongolia\n",
      "6. Hong Kong\n",
      "7. Viet Nam\n",
      "8. Thailand\n",
      "9. Singapore\n",
      "10. Malaysia\n",
      "\n",
      "And here are the corresponding areas for each of these countries:\n",
      "\n",
      "1. Asia\n",
      "2. Asia\n",
      "3. Asia\n",
      "4. Asia\n",
      "5. Asia\n",
      "6. Asia\n",
      "7. Asia\n",
      "8. Asia\n",
      "9. Asia\n",
      "10. Asia\n"
     ]
    }
   ],
   "source": [
    "res = agent.run(input=\" give me the 10 country name first and then give me the 10 area\",)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93be9c79-62c9-4291-a4cc-4e622b014c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am called\n"
     ]
    }
   ],
   "source": [
    "class MyTest:\n",
    "    def __call__(self):\n",
    "        self._call()\n",
    "\n",
    "    def _call(self):\n",
    "        print('I am called')\n",
    "\n",
    "# Create an instance\n",
    "mt = MyTest()\n",
    "\n",
    "# Call the instance\n",
    "mt()  # This will print 'I am called'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4475667-1c60-42db-8106-df24ca1a1f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'memory': None,\n",
       " 'verbose': True,\n",
       " 'tags': None,\n",
       " 'metadata': None,\n",
       " 'agent': {'runnable': {'name': None,\n",
       "   'first': {'name': None,\n",
       "    'mapper': {'name': None,\n",
       "     'steps__': {'agent_scratchpad': RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))}}},\n",
       "   'middle': [{'name': None,\n",
       "     'input_variables': ['agent_scratchpad', 'input'],\n",
       "     'optional_variables': [],\n",
       "     'output_parser': None,\n",
       "     'partial_variables': {},\n",
       "     'metadata': None,\n",
       "     'tags': None,\n",
       "     'messages': [{'content': '\\nYou are working with a pandas dataframe in Python. The name of the dataframe is `df`.\\nThis is the result of `print(df.head())`:\\n|    |   Unnamed: 0 |   Country | Country_name   | Area   |\\n|---:|-------------:|----------:|:---------------|:-------|\\n|  0 |            0 |       103 | Korea          | Asia   |\\n|  1 |            1 |       104 | North_Korea    | Asia   |\\n|  2 |            2 |       105 | China          | Asia   |\\n|  3 |            3 |       106 | Taiwan         | Asia   |\\n|  4 |            4 |       107 | Mongolia       | Asia   |',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {},\n",
       "       'type': 'system',\n",
       "       'name': None,\n",
       "       'id': None},\n",
       "      {'prompt': {'name': None,\n",
       "        'input_variables': ['input'],\n",
       "        'optional_variables': [],\n",
       "        'output_parser': None,\n",
       "        'partial_variables': {},\n",
       "        'metadata': None,\n",
       "        'tags': None,\n",
       "        'template': '{input}',\n",
       "        'template_format': 'f-string',\n",
       "        'validate_template': False,\n",
       "        '_type': 'prompt'},\n",
       "       'additional_kwargs': {}},\n",
       "      {'variable_name': 'agent_scratchpad',\n",
       "       'optional': False,\n",
       "       'n_messages': None}],\n",
       "     'validate_template': False,\n",
       "     '_type': 'chat'},\n",
       "    {'name': None,\n",
       "     'bound': {'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "      'model': 'gpt-4o-mini-2024-07-18',\n",
       "      'stream': False,\n",
       "      'n': 1,\n",
       "      'temperature': 0.7,\n",
       "      'logprobs': False,\n",
       "      '_type': 'openai-chat'},\n",
       "     'kwargs': {'tools': [{'type': 'function',\n",
       "        'function': {'name': 'python_repl_ast',\n",
       "         'description': 'A Python shell. Use this to execute python commands. Input should be a valid python command. When using this tool, sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.',\n",
       "         'parameters': {'type': 'object',\n",
       "          'properties': {'query': {'description': 'code snippet to run',\n",
       "            'type': 'string'}},\n",
       "          'required': ['query']}}}]},\n",
       "     'config': {},\n",
       "     'config_factories': [],\n",
       "     'custom_input_type': None,\n",
       "     'custom_output_type': None}],\n",
       "   'last': {'name': None, '_type': 'tools-agent-output-parser'}},\n",
       "  'input_keys_arg': ['input'],\n",
       "  'return_keys_arg': ['output'],\n",
       "  'stream_runnable': True},\n",
       " 'tools': [{'name': 'python_repl_ast',\n",
       "   'description': 'A Python shell. Use this to execute python commands. Input should be a valid python command. When using this tool, sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.',\n",
       "   'args_schema': langchain_experimental.tools.python.tool.PythonInputs,\n",
       "   'return_direct': True,\n",
       "   'verbose': False,\n",
       "   'tags': None,\n",
       "   'metadata': None,\n",
       "   'handle_tool_error': False,\n",
       "   'handle_validation_error': False,\n",
       "   'response_format': 'content',\n",
       "   'globals': {'__builtins__': {'__name__': 'builtins',\n",
       "     '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
       "     '__package__': '',\n",
       "     '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "     '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
       "     '__build_class__': <function __build_class__>,\n",
       "     '__import__': <function __import__>,\n",
       "     'abs': <function abs(x, /)>,\n",
       "     'all': <function all(iterable, /)>,\n",
       "     'any': <function any(iterable, /)>,\n",
       "     'ascii': <function ascii(obj, /)>,\n",
       "     'bin': <function bin(number, /)>,\n",
       "     'breakpoint': <function breakpoint>,\n",
       "     'callable': <function callable(obj, /)>,\n",
       "     'chr': <function chr(i, /)>,\n",
       "     'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "     'delattr': <function delattr(obj, name, /)>,\n",
       "     'dir': <function dir>,\n",
       "     'divmod': <function divmod(x, y, /)>,\n",
       "     'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "     'exec': <function exec(source, globals=None, locals=None, /)>,\n",
       "     'format': <function format(value, format_spec='', /)>,\n",
       "     'getattr': <function getattr>,\n",
       "     'globals': <function globals()>,\n",
       "     'hasattr': <function hasattr(obj, name, /)>,\n",
       "     'hash': <function hash(obj, /)>,\n",
       "     'hex': <function hex(number, /)>,\n",
       "     'id': <function id(obj, /)>,\n",
       "     'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7f0232479fa0>>,\n",
       "     'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "     'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "     'iter': <function iter>,\n",
       "     'len': <function len(obj, /)>,\n",
       "     'locals': <function locals()>,\n",
       "     'max': <function max>,\n",
       "     'min': <function min>,\n",
       "     'next': <function next>,\n",
       "     'oct': <function oct(number, /)>,\n",
       "     'ord': <function ord(c, /)>,\n",
       "     'pow': <function pow(base, exp, mod=None)>,\n",
       "     'print': <function print>,\n",
       "     'repr': <function repr(obj, /)>,\n",
       "     'round': <function round(number, ndigits=None)>,\n",
       "     'setattr': <function setattr(obj, name, value, /)>,\n",
       "     'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "     'sum': <function sum(iterable, /, start=0)>,\n",
       "     'vars': <function vars>,\n",
       "     'None': None,\n",
       "     'Ellipsis': Ellipsis,\n",
       "     'NotImplemented': NotImplemented,\n",
       "     'False': False,\n",
       "     'True': True,\n",
       "     'bool': bool,\n",
       "     'memoryview': memoryview,\n",
       "     'bytearray': bytearray,\n",
       "     'bytes': bytes,\n",
       "     'classmethod': classmethod,\n",
       "     'complex': complex,\n",
       "     'dict': dict,\n",
       "     'enumerate': enumerate,\n",
       "     'filter': filter,\n",
       "     'float': float,\n",
       "     'frozenset': frozenset,\n",
       "     'property': property,\n",
       "     'int': int,\n",
       "     'list': list,\n",
       "     'map': map,\n",
       "     'object': object,\n",
       "     'range': range,\n",
       "     'reversed': reversed,\n",
       "     'set': set,\n",
       "     'slice': slice,\n",
       "     'staticmethod': staticmethod,\n",
       "     'str': str,\n",
       "     'super': super,\n",
       "     'tuple': tuple,\n",
       "     'type': type,\n",
       "     'zip': zip,\n",
       "     '__debug__': True,\n",
       "     'BaseException': BaseException,\n",
       "     'Exception': Exception,\n",
       "     'TypeError': TypeError,\n",
       "     'StopAsyncIteration': StopAsyncIteration,\n",
       "     'StopIteration': StopIteration,\n",
       "     'GeneratorExit': GeneratorExit,\n",
       "     'SystemExit': SystemExit,\n",
       "     'KeyboardInterrupt': KeyboardInterrupt,\n",
       "     'ImportError': ImportError,\n",
       "     'ModuleNotFoundError': ModuleNotFoundError,\n",
       "     'OSError': OSError,\n",
       "     'EnvironmentError': OSError,\n",
       "     'IOError': OSError,\n",
       "     'EOFError': EOFError,\n",
       "     'RuntimeError': RuntimeError,\n",
       "     'RecursionError': RecursionError,\n",
       "     'NotImplementedError': NotImplementedError,\n",
       "     'NameError': NameError,\n",
       "     'UnboundLocalError': UnboundLocalError,\n",
       "     'AttributeError': AttributeError,\n",
       "     'SyntaxError': SyntaxError,\n",
       "     'IndentationError': IndentationError,\n",
       "     'TabError': TabError,\n",
       "     'LookupError': LookupError,\n",
       "     'IndexError': IndexError,\n",
       "     'KeyError': KeyError,\n",
       "     'ValueError': ValueError,\n",
       "     'UnicodeError': UnicodeError,\n",
       "     'UnicodeEncodeError': UnicodeEncodeError,\n",
       "     'UnicodeDecodeError': UnicodeDecodeError,\n",
       "     'UnicodeTranslateError': UnicodeTranslateError,\n",
       "     'AssertionError': AssertionError,\n",
       "     'ArithmeticError': ArithmeticError,\n",
       "     'FloatingPointError': FloatingPointError,\n",
       "     'OverflowError': OverflowError,\n",
       "     'ZeroDivisionError': ZeroDivisionError,\n",
       "     'SystemError': SystemError,\n",
       "     'ReferenceError': ReferenceError,\n",
       "     'MemoryError': MemoryError,\n",
       "     'BufferError': BufferError,\n",
       "     'Warning': Warning,\n",
       "     'UserWarning': UserWarning,\n",
       "     'DeprecationWarning': DeprecationWarning,\n",
       "     'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "     'SyntaxWarning': SyntaxWarning,\n",
       "     'RuntimeWarning': RuntimeWarning,\n",
       "     'FutureWarning': FutureWarning,\n",
       "     'ImportWarning': ImportWarning,\n",
       "     'UnicodeWarning': UnicodeWarning,\n",
       "     'BytesWarning': BytesWarning,\n",
       "     'ResourceWarning': ResourceWarning,\n",
       "     'ConnectionError': ConnectionError,\n",
       "     'BlockingIOError': BlockingIOError,\n",
       "     'BrokenPipeError': BrokenPipeError,\n",
       "     'ChildProcessError': ChildProcessError,\n",
       "     'ConnectionAbortedError': ConnectionAbortedError,\n",
       "     'ConnectionRefusedError': ConnectionRefusedError,\n",
       "     'ConnectionResetError': ConnectionResetError,\n",
       "     'FileExistsError': FileExistsError,\n",
       "     'FileNotFoundError': FileNotFoundError,\n",
       "     'IsADirectoryError': IsADirectoryError,\n",
       "     'NotADirectoryError': NotADirectoryError,\n",
       "     'InterruptedError': InterruptedError,\n",
       "     'PermissionError': PermissionError,\n",
       "     'ProcessLookupError': ProcessLookupError,\n",
       "     'TimeoutError': TimeoutError,\n",
       "     'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "     'copyright': Copyright (c) 2001-2021 Python Software Foundation.\n",
       "     All Rights Reserved.\n",
       "     \n",
       "     Copyright (c) 2000 BeOpen.com.\n",
       "     All Rights Reserved.\n",
       "     \n",
       "     Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "     All Rights Reserved.\n",
       "     \n",
       "     Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "     All Rights Reserved.,\n",
       "     'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "         for supporting Python development.  See www.python.org for more information.,\n",
       "     'license': Type license() to see the full license text,\n",
       "     'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "     'execfile': <function _pydev_bundle._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "     'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "     '__IPYTHON__': True,\n",
       "     'display': <function IPython.core.display_functions.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, raw=False, clear=False, **kwargs)>,\n",
       "     'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f0221752e20>>}},\n",
       "   'locals': {'df':      Unnamed: 0  Country                    Country_name  \\\n",
       "    0             0      103                           Korea   \n",
       "    1             1      104                     North_Korea   \n",
       "    2             2      105                           China   \n",
       "    3             3      106                          Taiwan   \n",
       "    4             4      107                        Mongolia   \n",
       "    ..          ...      ...                             ...   \n",
       "    227         227      627  Northern_Mariana_Islands_(USA)   \n",
       "    228         228      628                           Palau   \n",
       "    229         229      701                       For_Order   \n",
       "    230         230      702                         Unknown   \n",
       "    231         231      703  Bonded_Manufacturing_Warehouse   \n",
       "    \n",
       "                                     Area  \n",
       "    0                                Asia  \n",
       "    1                                Asia  \n",
       "    2                                Asia  \n",
       "    3                                Asia  \n",
       "    4                                Asia  \n",
       "    ..                                ...  \n",
       "    227                           Oceania  \n",
       "    228                           Oceania  \n",
       "    229                      Special_Area  \n",
       "    230                      Special_Area  \n",
       "    231  Integrated_Hozei_Ar_Special_Area  \n",
       "    \n",
       "    [232 rows x 4 columns]},\n",
       "   'sanitize_input': True}],\n",
       " 'return_intermediate_steps': False,\n",
       " 'max_iterations': 15,\n",
       " 'max_execution_time': None,\n",
       " 'early_stopping_method': 'force',\n",
       " 'handle_parsing_errors': False,\n",
       " 'trim_intermediate_steps': -1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9b16b-5140-46d4-bff1-403f785f3908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaeda7c4-f216-4caf-9a12-3fde583cb064",
   "metadata": {},
   "source": [
    "- _iter_next_step :  Override this to take control of how the agent makes and acts on choices.Take a single step in the thought-action-observation loop\n",
    "    - inputs: Dict[str, str] \n",
    "    - intermediate_steps: List[Tuple[AgentAction, str]]\n",
    "    - intermediate_steps = self._prepare_intermediate_steps(intermediate_steps)\n",
    "    - output = self.agent.plan(intermediate_steps,callbacks=run_manager.get_child() if run_manager else None,\n",
    "                **inputs, )\n",
    "    \n",
    "- self._perform_agent_action-> AgentStep:\n",
    "    - tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "    - if return_direct: tool_run_kwargs[\"llm_prefix\"] = \"\"\n",
    "    - observation = tool.run(agent_action.tool_input, **tool_run_kwargs)\n",
    "    - AgentStep(action=agent_action, observation=observation)\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f9c24-7414-444e-a731-7e09faa54393",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain/blob/02c35da445b5a8cbd3d47ba468243f9297795124/libs/langchain/langchain/agents/react/agent.py#L13\n",
    "def create_react_agent(\n",
    "    llm: BaseLanguageModel,\n",
    "    tools: Sequence[BaseTool],\n",
    "    prompt: BasePromptTemplate,\n",
    "    output_parser: Optional[AgentOutputParser] = None,\n",
    "    tools_renderer: ToolsRenderer = render_text_description,\n",
    "    *,\n",
    "    stop_sequence: Union[bool, List[str]] = True,\n",
    ") -> Runnable:\n",
    "    \"\"\"Create an agent that uses ReAct prompting.\n",
    "\n",
    "    Based on paper \"ReAct: Synergizing Reasoning and Acting in Language Models\"\n",
    "    (https://arxiv.org/abs/2210.03629)\n",
    "\n",
    "    Args:\n",
    "        llm: LLM to use as the agent.\n",
    "        tools: Tools this agent has access to.\n",
    "        prompt: The prompt to use. See Prompt section below for more.\n",
    "        output_parser: AgentOutputParser for parse the LLM output.\n",
    "        tools_renderer: This controls how the tools are converted into a string and\n",
    "            then passed into the LLM. Default is `render_text_description`.\n",
    "        stop_sequence: bool or list of str.\n",
    "            If True, adds a stop token of \"Observation:\" to avoid hallucinates.\n",
    "            If False, does not add a stop token.\n",
    "            If a list of str, uses the provided list as the stop tokens.\n",
    "\n",
    "            Default is True. You may to set this to False if the LLM you are using\n",
    "            does not support stop sequences.\n",
    "\n",
    "    Returns:\n",
    "        A Runnable sequence representing an agent. It takes as input all the same input\n",
    "        variables as the prompt passed in does. It returns as output either an\n",
    "        AgentAction or AgentFinish.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain import hub\n",
    "            from langchain_community.llms import OpenAI\n",
    "            from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "            prompt = hub.pull(\"hwchase17/react\")\n",
    "            model = OpenAI()\n",
    "            tools = ...\n",
    "\n",
    "            agent = create_react_agent(model, tools, prompt)\n",
    "            agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "            agent_executor.invoke({\"input\": \"hi\"})\n",
    "\n",
    "            # Use with chat history\n",
    "            from langchain_core.messages import AIMessage, HumanMessage\n",
    "            agent_executor.invoke(\n",
    "                {\n",
    "                    \"input\": \"what's my name?\",\n",
    "                    # Notice that chat_history is a string\n",
    "                    # since this prompt is aimed at LLMs, not chat models\n",
    "                    \"chat_history\": \"Human: My name is Bob\\\\nAI: Hello Bob!\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "    Prompt:\n",
    "\n",
    "        The prompt must have input keys:\n",
    "            * `tools`: contains descriptions and arguments for each tool.\n",
    "            * `tool_names`: contains all tool names.\n",
    "            * `agent_scratchpad`: contains previous agent actions and tool outputs as a string.\n",
    "\n",
    "        Here's an example:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "            template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "            {tools}\n",
    "\n",
    "            Use the following format:\n",
    "\n",
    "            Question: the input question you must answer\n",
    "            Thought: you should always think about what to do\n",
    "            Action: the action to take, should be one of [{tool_names}]\n",
    "            Action Input: the input to the action\n",
    "            Observation: the result of the action\n",
    "            ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "            Thought: I now know the final answer\n",
    "            Final Answer: the final answer to the original input question\n",
    "\n",
    "            Begin!\n",
    "\n",
    "            Question: {input}\n",
    "            Thought:{agent_scratchpad}'''\n",
    "\n",
    "            prompt = PromptTemplate.from_template(template)\n",
    "    \"\"\"  # noqa: E501\n",
    "    missing_vars = {\"tools\", \"tool_names\", \"agent_scratchpad\"}.difference(\n",
    "        prompt.input_variables + list(prompt.partial_variables)\n",
    "    )\n",
    "    if missing_vars:\n",
    "        raise ValueError(f\"Prompt missing required variables: {missing_vars}\")\n",
    "\n",
    "    prompt = prompt.partial(\n",
    "        tools=tools_renderer(list(tools)),\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    "    )\n",
    "    if stop_sequence:\n",
    "        stop = [\"\\nObservation\"] if stop_sequence is True else stop_sequence\n",
    "        llm_with_stop = llm.bind(stop=stop)  ##### UNDERSTAND THIS IN DETAIL ############################\n",
    "    else:\n",
    "        llm_with_stop = llm\n",
    "    output_parser = output_parser or ReActSingleInputOutputParser()\n",
    "    agent = (\n",
    "        RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        )\n",
    "        | prompt\n",
    "        | llm_with_stop\n",
    "        | output_parser\n",
    "    )\n",
    "    return agent\n",
    "    \n",
    "SINCE LLM IS A RUNNABEL WE UNDERSTAND RUNNNABLE AND THE BIND OPERATION TO RUNNABLE FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e55bffae-53fb-46c4-960d-a86e5a0d90e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools_renderer: ToolsRenderer = render_text_description\n",
    "# https://github.com/langchain-ai/langchain/blob/02c35da445b5a8cbd3d47ba468243f9297795124/libs/core/langchain_core/tools.py#L1352\n",
    "from inspect import signature\n",
    "\n",
    "def render_text_description_and_args(tools) -> str:\n",
    "    \"\"\"Render the tool name, description, and args in plain text.\n",
    "\n",
    "    Args:\n",
    "        tools: The tools to render.\n",
    "\n",
    "    Returns:\n",
    "        The rendered text.\n",
    "\n",
    "    Output will be in the format of:\n",
    "\n",
    "    .. code-block:: markdown\n",
    "\n",
    "        search: This tool is used for search, args: {\"query\": {\"type\": \"string\"}}\n",
    "        calculator: This tool is used for math, \\\n",
    "args: {\"expression\": {\"type\": \"string\"}}\n",
    "    \"\"\"\n",
    "    tool_strings = []\n",
    "    for tool in tools:\n",
    "        args_schema = str(tool.args)\n",
    "        if hasattr(tool, \"func\") and tool.func:\n",
    "            sig = signature(tool.func)\n",
    "            description = f\"{tool.name}{sig} - {tool.description}\"\n",
    "        else:\n",
    "            description = f\"{tool.name} - {tool.description}\"\n",
    "        tool_strings.append(f\"{description}, args: {args_schema}\")\n",
    "    return \"\\n\".join(tool_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9989501-432d-49cd-829b-f280f3c30bcd",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain/blob/02c35da445b5a8cbd3d47ba468243f9297795124/libs/core/langchain_core/tools.py#L1352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f1f246d-3d01-4f9a-8163-592f36718fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool\n",
    "def render_text_description(tools: List[BaseTool]) -> str:\n",
    "    \"\"\"Render the tool name and description in plain text.\n",
    "\n",
    "    Args:\n",
    "        tools: The tools to render.\n",
    "\n",
    "    Returns:\n",
    "        The rendered text.\n",
    "\n",
    "    Output will be in the format of:\n",
    "\n",
    "    .. code-block:: markdown\n",
    "\n",
    "        search: This tool is used for search\n",
    "        calculator: This tool is used for math\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "    for tool in tools:\n",
    "        if hasattr(tool, \"func\") and tool.func:\n",
    "            sig = signature(tool.func)\n",
    "            description = f\"{tool.name}{sig} - {tool.description}\"\n",
    "        else:\n",
    "            description = f\"{tool.name} - {tool.description}\"\n",
    "\n",
    "        descriptions.append(description)\n",
    "    return \"\\n\".join(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c927d95-237a-4a7c-a7d9-c8c1a4d64beb",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain/blob/02c35da445b5a8cbd3d47ba468243f9297795124/libs/langchain/langchain/agents/format_scratchpad/log.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8238ba60-b8c4-4ea1-9db9-4d94e758dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentAction\n",
    "\n",
    "\n",
    "def format_log_to_str(\n",
    "    intermediate_steps: List[Tuple[AgentAction, str]],\n",
    "    observation_prefix: str = \"Observation: \",\n",
    "    llm_prefix: str = \"Thought: \",\n",
    ") -> str:\n",
    "    \"\"\"Construct the scratchpad that lets the agent continue its thought process.\n",
    "\n",
    "    Args:\n",
    "        intermediate_steps: List of tuples of AgentAction and observation strings.\n",
    "        observation_prefix: Prefix to append the observation with.\n",
    "             Defaults to \"Observation: \".\n",
    "        llm_prefix: Prefix to append the llm call with.\n",
    "                Defaults to \"Thought: \".\n",
    "\n",
    "    Returns:\n",
    "        str: The scratchpad.\n",
    "    \"\"\"\n",
    "    thoughts = \"\"\n",
    "    for action, observation in intermediate_steps:\n",
    "        thoughts += action.log\n",
    "        thoughts += f\"\\n{observation_prefix}{observation}\\n{llm_prefix}\"\n",
    "    return thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3713b5ea-85b2-46a0-8997-114b9be9e123",
   "metadata": {},
   "source": [
    "- In this case agent is just a chain of:  input_data_dict | passthrough_with_addl_key | promt| model| parser\n",
    "- The input_data_dict is having a key: intermidiate_steps\n",
    "- passthrough_with_addl_key: agent_scratchpad whose value is formatted thought and observation intermidiate_steps\n",
    "- this dict goes to prompt to fill up the variables in the prmpt\n",
    "- prompt goes to model\n",
    "- output of the model is parsed\n",
    "- we need to find who is calling this agent.invoke with the assumed input_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1c75c50-0a87-4ff7-ac0f-6590b17625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.prompts import BasePromptTemplate\n",
    "from langchain.agents import AgentOutputParser\n",
    "\n",
    "from langchain.tools.render import ToolsRenderer, render_text_description\n",
    "\n",
    "def create_react_agent(\n",
    "    llm: BaseLanguageModel,\n",
    "    tools: Sequence[BaseTool],\n",
    "    prompt: BasePromptTemplate,\n",
    "    output_parser: Optional[AgentOutputParser] = None,\n",
    "    tools_renderer: ToolsRenderer = render_text_description,\n",
    "    *,\n",
    "    stop_sequence: Union[bool, List[str]] = True,\n",
    ") -> Runnable:\n",
    "    missing_vars = {\"tools\", \"tool_names\", \"agent_scratchpad\"}.difference(\n",
    "            prompt.input_variables + list(prompt.partial_variables)\n",
    "        )\n",
    "    if missing_vars:\n",
    "        raise ValueError(f\"Prompt missing required variables: {missing_vars}\")\n",
    "\n",
    "    prompt = prompt.partial(\n",
    "        tools=tools_renderer(list(tools)),\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    "    )\n",
    "    if stop_sequence:\n",
    "        stop = [\"\\nObservation\"] if stop_sequence is True else stop_sequence\n",
    "        llm_with_stop = llm.bind(stop=stop)\n",
    "    else:\n",
    "        llm_with_stop = llm\n",
    "    output_parser = output_parser or ReActSingleInputOutputParser()\n",
    "    agent = (\n",
    "        RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        )\n",
    "        | prompt\n",
    "        | llm_with_stop\n",
    "        | output_parser\n",
    "    )\n",
    "    return agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c09538e8-9490-4f25-bef0-e4998168aa14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain/hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'] metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'} template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchainhub\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbc29d36-c70d-4e13-9c54-391e8df45e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BuyProductTool(), CalculateRevenueTool()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "import LC_tools as lctools\n",
    "import importlib\n",
    "importlib.reload(lctools)\n",
    "tools = lctools.tools\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae0485-eafa-4abc-b4e7-ba67bd9e90c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f68e53f9-4b7c-41ad-8125-caf7b978c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(openai_api_key=openai_api_key.get_secret_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7c7bb97-644e-4f8b-85e3-6377a0be792f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50cab733-cac7-4611-95b5-3778d3f9295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai_api_key': 'OPENAI_API_KEY'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lc_secrets  ### i have to look into this while studying the code for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a30c169-ed83-41b4-969b-ae772573d365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x7f02094804f0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7f0209509850>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  #### Note that the api key is hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fddffcc3-9106-4f52-bfcf-356137b0f9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SecretStr('**********')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "686fcb01-b484-4d00-a729-42c4f96d6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0699f7e0-bf55-4ca1-baa0-ac9713b1c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': 'buy_product -  the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    \\ncalculate_revenue -  returns revenue for the product or total revenue when no product name is mentione\\n    ', 'tool_names': 'buy_product, calculate_revenue'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=OpenAI(client=<openai.resources.completions.Completions object at 0x7f02094804f0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7f0209509850>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'stop': ['\\nObservation']})\n",
       "| ReActSingleInputOutputParser()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_react_agent(model, tools, prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d66e1c-e77b-4075-9e11-d990076b0121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f45773a-d1a7-468f-a18c-b78444f6c8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': 'buy_product -  the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    \\ncalculate_revenue -  returns revenue for the product or total revenue when no product name is mentione\\n    ', 'tool_names': 'buy_product, calculate_revenue'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=OpenAI(client=<openai.resources.completions.Completions object at 0x7f02094804f0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7f0209509850>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'stop': ['\\nObservation']})\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[BuyProductTool(), CalculateRevenueTool()], max_iterations=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, max_iterations=1)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f742104-cbbc-40c9-9f2c-f33a00301339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes={'7b31c20f790349dd85069715849b44fe': Node(id='7b31c20f790349dd85069715849b44fe', name='ChainInput', data=<class 'pydantic.v1.main.ChainInput'>, metadata=None), 'c728c80e4f664d948bb72923491f2a0c': Node(id='c728c80e4f664d948bb72923491f2a0c', name='AgentExecutor', data=AgentExecutor(agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': 'buy_product -  the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    \\ncalculate_revenue -  returns revenue for the product or total revenue when no product name is mentione\\n    ', 'tool_names': 'buy_product, calculate_revenue'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=OpenAI(client=<openai.resources.completions.Completions object at 0x7f02094804f0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7f0209509850>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'stop': ['\\nObservation']})\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[BuyProductTool(), CalculateRevenueTool()], max_iterations=1), metadata=None), '774df11a298c46d99b73579f11b402b2': Node(id='774df11a298c46d99b73579f11b402b2', name='ChainOutput', data=<class 'pydantic.v1.main.ChainOutput'>, metadata=None)}, edges=[Edge(source='7b31c20f790349dd85069715849b44fe', target='c728c80e4f664d948bb72923491f2a0c', data=None, conditional=False), Edge(source='c728c80e4f664d948bb72923491f2a0c', target='774df11a298c46d99b73579f11b402b2', data=None, conditional=False)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = agent_executor.get_graph()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "baf8ff2b-63fd-4122-b800-ae86a373348c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7b31c20f790349dd85069715849b44fe': Node(id='7b31c20f790349dd85069715849b44fe', name='ChainInput', data=<class 'pydantic.v1.main.ChainInput'>, metadata=None),\n",
       " 'c728c80e4f664d948bb72923491f2a0c': Node(id='c728c80e4f664d948bb72923491f2a0c', name='AgentExecutor', data=AgentExecutor(agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "   agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       " })\n",
       " | PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': 'buy_product -  the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    \\ncalculate_revenue -  returns revenue for the product or total revenue when no product name is mentione\\n    ', 'tool_names': 'buy_product, calculate_revenue'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       " | RunnableBinding(bound=OpenAI(client=<openai.resources.completions.Completions object at 0x7f02094804f0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7f0209509850>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'stop': ['\\nObservation']})\n",
       " | ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[BuyProductTool(), CalculateRevenueTool()], max_iterations=1), metadata=None),\n",
       " '774df11a298c46d99b73579f11b402b2': Node(id='774df11a298c46d99b73579f11b402b2', name='ChainOutput', data=<class 'pydantic.v1.main.ChainOutput'>, metadata=None)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fb976ca-d610-4b4d-92a3-f9ff9926d8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source='7b31c20f790349dd85069715849b44fe', target='c728c80e4f664d948bb72923491f2a0c', data=None, conditional=False),\n",
       " Edge(source='c728c80e4f664d948bb72923491f2a0c', target='774df11a298c46d99b73579f11b402b2', data=None, conditional=False)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30166f1c-96d6-490d-ada6-cd98c8575820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d5a1dd3-8d40-4825-b056-78d5273ac2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a wireless mouse\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"agent_scratchpad\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [19ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a wireless mouse\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a wireless mouse\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:OpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nbuy_product -  the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    \\ncalculate_revenue -  returns revenue for the product or total revenue when no product name is mentione\\n    \\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [buy_product, calculate_revenue]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: buy me a wireless mouse\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:OpenAI] [834ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Check if a wireless mouse is in stock and then buy it if it is\\nAction: buy_product\\nAction Input: wireless mouse\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ReActSingleInputOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \" Check if a wireless mouse is in stock and then buy it if it is\\nAction: buy_product\\nAction Input: wireless mouse\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ReActSingleInputOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [888ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:buy_product] Entering Tool run with input:\n",
      "\u001b[0m\"wireless mouse\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:buy_product] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"wireless mouse purchase confirmed. Remaining stock 96\"\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [936ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"wireless mouse purchase confirmed. Remaining stock 96\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'buy me a wireless mouse',\n",
       " 'output': 'wireless mouse purchase confirmed. Remaining stock 96'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "set_verbose(True)\n",
    "set_debug(True)\n",
    "agent_executor.invoke({\"input\": \"buy me a wireless mouse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08e746b2-462c-48f4-9503-92cfe737645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(AgentExecutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149c043-0e0e-4720-93ec-273dec05ab2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tool Calling Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788de740-d6f6-4362-a7ec-3a1033b5da73",
   "metadata": {},
   "source": [
    "tool_calling_agent - https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/tool_calling_agent/base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f1cc602-883b-45df-a6b0-24d5b9f6289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_core.agents import AgentAction\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def _create_tool_message(\n",
    "    agent_action: ToolAgentAction, observation: str\n",
    ") -> ToolMessage:\n",
    "    \"\"\"Convert agent action and observation into a tool message.\n",
    "\n",
    "    Args:\n",
    "        agent_action: the tool invocation request from the agent.\n",
    "        observation: the result of the tool invocation.\n",
    "    Returns:\n",
    "        ToolMessage that corresponds to the original tool invocation.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if the observation cannot be converted to a string.\n",
    "    \"\"\"\n",
    "    if not isinstance(observation, str):\n",
    "        try:\n",
    "            content = json.dumps(observation, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            content = str(observation)\n",
    "    else:\n",
    "        content = observation\n",
    "    return ToolMessage(\n",
    "        tool_call_id=agent_action.tool_call_id,\n",
    "        content=content,\n",
    "        additional_kwargs={\"name\": agent_action.tool},\n",
    "    )\n",
    "\n",
    "from langchain.agents.output_parsers.tools import ToolAgentAction\n",
    "def format_to_tool_messages(\n",
    "    intermediate_steps: Sequence[Tuple[AgentAction, str]],\n",
    ") -> List[BaseMessage]:\n",
    "    \"\"\"Convert (AgentAction, tool output) tuples into ToolMessages.\n",
    "\n",
    "    Args:\n",
    "        intermediate_steps: Steps the LLM has taken to date, along with observations.\n",
    "\n",
    "    Returns:\n",
    "        list of messages to send to the LLM for the next prediction.\n",
    "\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    for agent_action, observation in intermediate_steps:\n",
    "        if isinstance(agent_action, ToolAgentAction):\n",
    "            new_messages = list(agent_action.message_log) + [\n",
    "                _create_tool_message(agent_action, observation)\n",
    "            ]\n",
    "            messages.extend([new for new in new_messages if new not in messages])\n",
    "        else:\n",
    "            messages.append(AIMessage(content=agent_action.log))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f36efc8a-c1dd-462f-aa26-9e955007ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### see the only difference is bind_tools instead of tools_renderer and format_to_tool_messages\n",
    "# prompt = prompt.partial(\n",
    "#         tools=tools_renderer(list(tools)),\n",
    "#         tool_names=\", \".join([t.name for t in tools]),\n",
    "#     )\n",
    "\n",
    "\n",
    "MessageFormatter = Callable[[Sequence[Tuple[AgentAction, str]]], List[BaseMessage]]\n",
    "\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    llm: BaseLanguageModel,\n",
    "    tools: Sequence[BaseTool],\n",
    "    prompt: ChatPromptTemplate,\n",
    "    *,\n",
    "    message_formatter: MessageFormatter = format_to_tool_messages,\n",
    ") -> Runnable:\n",
    "    missing_vars = {\"agent_scratchpad\"}.difference(\n",
    "            prompt.input_variables + list(prompt.partial_variables)\n",
    "        )\n",
    "    if missing_vars:\n",
    "        raise ValueError(f\"Prompt missing required variables: {missing_vars}\")\n",
    "\n",
    "    if not hasattr(llm, \"bind_tools\"):\n",
    "        raise ValueError(\n",
    "            \"This function requires a .bind_tools method be implemented on the LLM.\",\n",
    "        )\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "    agent = (\n",
    "        RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: message_formatter(x[\"intermediate_steps\"])\n",
    "        )\n",
    "        | prompt\n",
    "        | llm_with_tools\n",
    "        | ToolsAgentOutputParser()\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f635d57-5f24-4c6c-a789-631608472c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afac8fa6-8037-478d-8581-64f5199fd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c064c0f-047d-4682-ac86-85caa6f058a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function requires a .bind_tools method be implemented on the LLM.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tool_calling_agent = create_tool_calling_agent(model, tools, prompt)\n",
    "    tool_calling_agent\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "852865af-3577-4f23-aac9-a03198c5bdff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f020953fd00>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f0209594f70>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'buy_product', 'description': ' the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}, {'type': 'function', 'function': {'name': 'calculate_revenue', 'description': ' returns revenue for the product or total revenue when no product name is mentione\\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}]})\n",
       "| ToolsAgentOutputParser()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmodel = ChatOpenAI(api_key=openai_api_key.get_secret_value())\n",
    "tool_calling_agent = create_tool_calling_agent(chatmodel, tools, prompt)\n",
    "tool_calling_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89fa1a-25a4-4c21-ad9b-8b0151b55e47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# understand what is bind_tools in chatmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9d9a2-1d03-49c0-8c5b-62f54d5d197e",
   "metadata": {},
   "source": [
    "bind_tool\n",
    "https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/chat_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88636b42-bf1b-45fa-9495-7e7f6ec8b3c6",
   "metadata": {},
   "source": [
    "base LLM - https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/llms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b517e8d3-fadf-4106-a815-b1e42f78cf13",
   "metadata": {},
   "source": [
    "BaseOpenAILLM - https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/llms/openai.py  ### should not use it , use the langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3c621d3-d136-4e4a-98ec-a48bdbb4936c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f020953fd00>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f0209594f70>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43c12486-a092-4728-b65e-632ba7344a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f020953fd00>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f0209594f70>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'buy_product', 'description': ' the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}, {'type': 'function', 'function': {'name': 'calculate_revenue', 'description': ' returns revenue for the product or total revenue when no product name is mentione\\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}]})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmodel.bind_tools(tools)  \n",
    "''' nothing but passing the arguments to the model in the following format\n",
    "tools=[ \n",
    "        {'type':function, \n",
    "         'function':{\n",
    "             'name': '', \n",
    "             'description': '', \n",
    "             'parameters': {\n",
    "                 'type': 'object', \n",
    "                 'properties': {\n",
    "                     'product_name': {\n",
    "                         'description': 'name of the product to be purchased', \n",
    "                         'type': 'string'\n",
    "                                    }\n",
    "                                }, \n",
    "                  'required': ['product_name']\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "           \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93e94e-0e58-40d3-b1fb-8e37e56fe383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remeber when tool is called with tool_call format  we get the contetn and artifact :\n",
    "'''\n",
    "tool_message = calculate_revenue_tool.invoke(\n",
    "    {\n",
    "        \"name\": \"calculate_revenue_tool\",\n",
    "        \"args\": {\"product_name\": \"mechanical keyboard\"},\n",
    "        \"id\": \"1\" , ## required field\n",
    "        \"type\": \"tool_call\", ## required field\n",
    "    }\n",
    ")     \n",
    "print('tool_message ...:', tool_message)\n",
    "tool_message ...: \n",
    "content='Revenue for mechanical keyboard: $6159.23' \n",
    "name='calculate_revenue' \n",
    "tool_call_id='1' \n",
    "artifact={'wireless mouse': 3898.4999999999995, 'mechanical keyboard': 6159.23, 'usb-c hub': 4198.8}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ffdd6ce-cb7c-491e-b02e-b7b8a023c196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BuyProductTool(), CalculateRevenueTool()]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd807ca-d179-4bd8-8734-6ef413629cbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# agent executor for tool calling falied with prompt having tools and tool_name as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1452027d-43e3-4dbc-9ebc-e2aecaddef46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f020953fd00>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f0209594f70>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'buy_product', 'description': ' the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}, {'type': 'function', 'function': {'name': 'calculate_revenue', 'description': ' returns revenue for the product or total revenue when no product name is mentione\\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}]})\n",
       "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[BuyProductTool(), CalculateRevenueTool()], max_iterations=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor_tool_calling = AgentExecutor(agent=tool_calling_agent, tools=tools, max_iterations=1)\n",
    "agent_executor_tool_calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16234b83-ceea-42c0-bcd0-aac0a9d1b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a shoe\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [19ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a shoe\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a shoe\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:PromptTemplate] [2ms] Prompt run errored with error:\n",
      "\u001b[0m\"KeyError(\\\"Input to PromptTemplate is missing variables {'tool_names', 'tools'}.  Expected: ['agent_scratchpad', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'agent_scratchpad']\\\")Traceback (most recent call last):\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1784, in _call_with_config\\n    context.run(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/config.py\\\", line 404, in call_func_with_variable_args\\n    return func(input, **kwargs)  # type: ignore[call-arg]\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/prompts/base.py\\\", line 153, in _format_prompt_with_error_handling\\n    _inner_input = self._validate_input(inner_input)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/prompts/base.py\\\", line 145, in _validate_input\\n    raise KeyError(\\n\\n\\nKeyError: \\\"Input to PromptTemplate is missing variables {'tool_names', 'tools'}.  Expected: ['agent_scratchpad', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'agent_scratchpad']\\\"\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [58ms] Chain run errored with error:\n",
      "\u001b[0m\"KeyError(\\\"Input to PromptTemplate is missing variables {'tool_names', 'tools'}.  Expected: ['agent_scratchpad', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'agent_scratchpad']\\\")Traceback (most recent call last):\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 2053, in _transform_stream_with_config\\n    chunk: Output = context.run(next, iterator)  # type: ignore\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 3202, in _transform\\n    for output in final_pipeline:\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1271, in transform\\n    for ichunk in input:\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 5267, in transform\\n    yield from self.bound.transform(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1271, in transform\\n    for ichunk in input:\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1289, in transform\\n    yield from self.stream(final, config, **kwargs)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 854, in stream\\n    yield self.invoke(input, config, **kwargs)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/prompts/base.py\\\", line 179, in invoke\\n    return self._call_with_config(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1784, in _call_with_config\\n    context.run(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/config.py\\\", line 404, in call_func_with_variable_args\\n    return func(input, **kwargs)  # type: ignore[call-arg]\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/prompts/base.py\\\", line 153, in _format_prompt_with_error_handling\\n    _inner_input = self._validate_input(inner_input)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/prompts/base.py\\\", line 145, in _validate_input\\n    raise KeyError(\\n\\n\\nKeyError: \\\"Input to PromptTemplate is missing variables {'tool_names', 'tools'}.  Expected: ['agent_scratchpad', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'agent_scratchpad']\\\"\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:AgentExecutor] [110ms] Chain run errored with error:\n",
      "\u001b[0m\"KeyError(\\\"Input to PromptTemplate is missing variables {'tool_names', 'tools'}.  Expected: ['agent_scratchpad', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'agent_scratchpad']\\\")Traceback (most recent call last):\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain/chains/base.py\\\", line 156, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain/agents/agent.py\\\", line 1612, in _call\\n    next_step_output = self._take_next_step(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain/agents/agent.py\\\", line 1318, in _take_next_step\\n    [\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain/agents/agent.py\\\", line 1318, in <listcomp>\\n    [\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain/agents/agent.py\\\", line 1346, in _iter_next_step\\n    output = self.agent.plan(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain/agents/agent.py\\\", line 580, in plan\\n    for chunk in self.runnable.stream(inputs, config={\\\"callbacks\\\": callbacks}):\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 3253, in stream\\n    yield from self.transform(iter([input]), config, **kwargs)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 3240, in transform\\n    yield from self._transform_stream_with_config(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 2053, in _transform_stream_with_config\\n    chunk: Output = context.run(next, iterator)  # type: ignore\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 3202, in _transform\\n    for output in final_pipeline:\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1271, in transform\\n    for ichunk in input:\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 5267, in transform\\n    yield from self.bound.transform(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1271, in transform\\n    for ichunk in input:\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1289, in transform\\n    yield from self.stream(final, config, **kwargs)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 854, in stream\\n    yield self.invoke(input, config, **kwargs)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/prompts/base.py\\\", line 179, in invoke\\n    return self._call_with_config(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py\\\", line 1784, in _call_with_config\\n    context.run(\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/runnables/config.py\\\", line 404, in call_func_with_variable_args\\n    return func(input, **kwargs)  # type: ignore[call-arg]\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/prompts/base.py\\\", line 153, in _format_prompt_with_error_handling\\n    _inner_input = self._validate_input(inner_input)\\n\\n\\n  File \\\"/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/prompts/base.py\\\", line 145, in _validate_input\\n    raise KeyError(\\n\\n\\nKeyError: \\\"Input to PromptTemplate is missing variables {'tool_names', 'tools'}.  Expected: ['agent_scratchpad', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'agent_scratchpad']\\\"\"\n",
      "\"Input to PromptTemplate is missing variables {'tool_names', 'tools'}.  Expected: ['agent_scratchpad', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'agent_scratchpad']\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    agent_executor.invoke({\"input\": \"buy me a shoe\"})\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525457f-fc67-4c75-acc7-0fd088633a74",
   "metadata": {},
   "source": [
    "# Modified prompt for tool_calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3def93e9-6193-42d2-9a57-879120066838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "deb74ab3-bdb4-4f2a-9111-e3ff39de22f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': [], 'tool_names': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calling_prompt = prompt.partial(tools=[], tool_names=[])\n",
    "tool_calling_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66b60ebd-a96d-425a-b89a-ff7f7fc4902d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': [], 'tool_names': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f020953fd00>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f0209594f70>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'buy_product', 'description': ' the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}, {'type': 'function', 'function': {'name': 'calculate_revenue', 'description': ' returns revenue for the product or total revenue when no product name is mentione\\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}]})\n",
       "| ToolsAgentOutputParser()"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "tool_calling_agent_newprompt = create_tool_calling_agent(chatmodel, tools, tool_calling_prompt)\n",
    "tool_calling_agent_newprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "52d3c385-e302-4d4a-893c-ddf280e03236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f020953fd00>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f0209594f70>, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'buy_product', 'description': ' the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}, {'type': 'function', 'function': {'name': 'calculate_revenue', 'description': ' returns revenue for the product or total revenue when no product name is mentione\\n    ', 'parameters': {'type': 'object', 'properties': {'product_name': {'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}}}]})\n",
       "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[BuyProductTool(), CalculateRevenueTool()], max_iterations=1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor_tool_calling_newprompt = AgentExecutor(agent=tool_calling_agent, tools=tools, max_iterations=1)\n",
    "agent_executor_tool_calling_newprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c7ad780-9832-4586-8c8a-508c91bd21bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a usb-c hub \"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"agent_scratchpad\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [19ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a usb-c hub \",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"buy me a usb-c hub \",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:OpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nbuy_product -  the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    \\ncalculate_revenue -  returns revenue for the product or total revenue when no product name is mentione\\n    \\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [buy_product, calculate_revenue]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: buy me a usb-c hub \\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:OpenAI] [897ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Verify the current stock level of the product.\\nAction: buy_product\\nAction Input: usb-c hub\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ReActSingleInputOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \" Verify the current stock level of the product.\\nAction: buy_product\\nAction Input: usb-c hub\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ReActSingleInputOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [948ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:buy_product] Entering Tool run with input:\n",
      "\u001b[0m\"usb-c hub\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:buy_product] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"usb-c hub purchase confirmed. Remaining stock 1\"\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [997ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"usb-c hub purchase confirmed. Remaining stock 1\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'buy me a usb-c hub ',\n",
       " 'output': 'usb-c hub purchase confirmed. Remaining stock 1'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor_tool_calling_newprompt.invoke({\"input\": \"buy me a usb-c hub \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e5cc6-4d69-4f27-92d7-df13d4e0a2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422ccdb-fd96-40cc-a3ca-eb782489efed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
